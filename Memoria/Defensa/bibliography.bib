% Artículo principal: Multilayer feedforward networks are universal approximators
@article{HORNIK1989359,
    title = {Multilayer feedforward networks are universal approximators},
    journal = {Neural Networks},
    volume = {2},
    number = {5},
    pages = {359-366},
    year = {1989},
    issn = {0893-6080},
    doi = {https://doi.org/10.1016/0893-6080(89)90020-8},
    url = {https://www.sciencedirect.com/science/article/pii/0893608089900208},
    author = {Kurt Hornik and Maxwell Stinchcombe and Halbert White},
    keywords = {Feedforward networks, Universal approximation, Mapping networks, Network representation capability, Stone-Weierstrass Theorem, Squashing functions, Sigma-Pi networks, Back-propagation networks},
    abstract = {This paper rigorously establishes that standard multilayer feedforward networks with as few as one hidden layer using arbitrary squashing functions are capable of approximating any Borel measurable function from one finite dimensional space to another to any desired degree of accuracy, provided sufficiently many hidden units are available. In this sense, multilayer feedforward networks are a class of universal approximators.}
}
% Teoría de aprendizaje automático
@book{MostafaLearningFromData,  
author = {Abu-Mostafa, Yaser S. and Magdon-Ismail, Malik and Lin, Hsuan-Tien}, 
title = {Learning From Data}, 
year = {2012}, 
isbn = {1600490069},
 publisher = {AMLBook}, 
 abstract = {Machine learning allows computational systems to adaptively 
 improve their performance with experience accumulated from the observed
data. Its techniques are widely applied in engineering, science, finance, and commerce.
This book is designed for a short course on machine learning. It is a short course, not 
a hurried course. From over a decade of teaching this material, we have distilled what
we believe to be the core topics that every student of the subject should know. 
We chose the title `learning from data' that faithfully describes what the subject 
is about, and made it a point to cover the topics in a story-like fashion. 
Our hope is that the reader can learn all the fundamentals of the subject by 
reading the book cover to cover. ---- Learning from data has distinct theoretical
and practical tracks. In this book, we balance the theoretical and the practical,
the mathematical and the heuristic. Our criterion for inclusion is relevance. 
Theory that establishes the conceptual framework for learning is included, 
and so are heuristics that impact the performance of real learning systems. 
---- Learning from data is a very dynamic field. Some of the hot techniques
and theories at times become just fads, and others gain traction and become
part of the field. What we have emphasized in this book are the necessary 
fundamentals that give any student of learning from data a solid foundation,
and enable him or her to venture out and explore further techniques and theories, 
or perhaps to contribute their own. ---- The authors are professors at California 
Institute of Technology (Caltech), Rensselaer Polytechnic Institute (RPI), 
and National Taiwan University (NTU), where this book is the main text for 
their popular courses on machine learning. The authors also consult extensively 
with financial and commercial companies on machine learning applications,
and have led winning teams in machine learning competitions.}          
}

% Teoría de la aproximación 
@book{the-elements-of-real-analysis,
  title={The elements of real analysis},
  author={Robert G. Bartle},
  year={1947},
  publisher={John. Wiley \& Sons}
}