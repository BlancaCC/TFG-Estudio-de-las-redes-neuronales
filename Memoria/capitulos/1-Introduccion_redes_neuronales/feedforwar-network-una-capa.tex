% !TeX encoding = utf8
%
%*******************************************************
% Construcción redes neuronales  una capa 
%*******************************************************

\section{Definición de las redes neuronales \textit{Feedforward Networks} 
de una capa oculta} \label{sec:redes-neuronales-intro-una-capa}

A lo largo de esta sección  explicaremos qué es una red neuronal, cómo está construida y en qué consiste el \textit{aprendizaje} de la misma, concretamente
construiremos el tipo particular \textit{Feedforward Networks}, al cual nos referiremos de ahora
en adelante como red neuronal.

De acorde con nuestra filosofía de trabajo, partir de un modelo de una sola capa oculta. 
La información que se va a desarrollar a lo largo de esta 
sección proviene principalmente del capítulo cinco, páginas 227-256 del libro \cite{BishopPaterRecognition} y las notas online sobre redes neuronales de \cite{MostafaLearningFromData}.

\begin{definicion}[Redes neuronales de una capa oculta]
    Dados $X \subseteq \R^d, Y \subseteq \R^s$ y  $\Gamma$ un conjunto no vacío de funciones medibles definido de $\R$ a $\R$, denotaremos como 
    \begin{align}
        \mathcal{H}(X,Y) 
        =
        \{
            h : X \longrightarrow Y 
            /& \quad 
            h_k(x) = 
            \sum_{i=1}^n \beta_i \gamma_i( A_i(x)), \\
            & \text{donde  $h_k$  es la proyección k-ésima de $h$ con 
            $k \in \{1, \ldots, s\}$}, \\
            & n \in \N,\gamma_i \in \Gamma , \beta_i \in \R
             \text{ y }A_i \text{ una aplicación afín de $\R^d$ a $\R$}           
        \}.
    \end{align}
\end{definicion}

Es habitual representar una red neuronal de forma matricial, veremos que tal forma es equivalente a la definición dada. 

Consideramos la aplicación inclusión 
$i: \R^r \longrightarrow \R^{r+1}$ dada por 
 $i((x_1, \ldots, x_d)) = (1,x_1, \ldots, x_d).$
Para coeficientes $w_i \in \R$ toda función afín es de la forma $A(x)= \sum_{i=1}^d( w_i x_i) + w_0$, 
tomando $W = (w_0, w_1, \ldots, w_r) \in \R^{r+1}$ tenemos que 
$A(x) = W \cdot i(x)$ como queríamos probar. 


\textcolor{red}{TODO Añadir gráfico ilustrativo.}


\textcolor{red}{TODO Comentar cómo se han relajado las hipótesis en nuestra definición con respecto a otras.}
