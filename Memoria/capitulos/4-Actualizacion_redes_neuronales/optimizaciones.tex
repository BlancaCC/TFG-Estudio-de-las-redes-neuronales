%%%%%%%%%%%%%%%%%%%
%%
%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Consideraciones para optimizar el aprendizaje }  

\subsection{ Inicialización de los pesos de una red neuronal}  

\textcolor{red}{Nota en sucio para que no se me olvide incluirla}  

El gradiente descendente pretende en cada 
paso acercarse más a la solución pero es 
totalmente sensible a la posición inicial 
de los pesos. Este método no solo servirá exclusivamente para le método de gradiente descendente 
sino para cualquier otro dependiente del punto inicial. 

Una vez fijado el número de neuronas se podría utilizar un proceso constructivo similar al que evoca la demostración \ref{teorema:2_5_entrenamiento_redes_neuronales}. 

\textcolor{red}{ TODO
Pensar método constructivo.} 

$p$ vector inicializado de manera aleatoria, con ¿valores bajos?,
(decir que no importa que ambos sean iguales p T)


\textcolor{red}{Cuando se compare con otros métodos hacerlo con: pesos aleatorios totalmente, con backbones y con este}

