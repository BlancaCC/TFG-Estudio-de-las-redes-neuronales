\section{Aprendizaje}  

Se entiende por aprendizaje de una red neuronal como el proceso 
por el cual se determina el valor sus pesos, es decir, lo que en el ejemplo \ref{img:Ejemplo-evaluación-red-neruonal-una-capa} consistía en las matrices $A,S$ y $B$.

%%%%%%%%%%%%%%%%%%% algoritmo de gradiente descendente 

\subsection{Método de gradiente descendente y \textit{backpropagation}} \label{sec:gradiente-descendente}

De acorde a los capítulos uno y dos del libro  \cite{learning-from-data-1-2},
 una vez concretado el problema y sus elementos 
(\ref{sub:componentes_aprendizaje}) es necesario definir un método con 
el que aproximar la función ideal $f,$ para ello introduciremos el algoritmo de gradiente descendente.  

El gradiente descendente es un método iterativo de minimización de funciones diferenciables. 

% Nota sobre el algoritmo de gradiente descendente 
\reversemarginpar
\marginpar{
    \textcolor{dark_green}{    
        \textbf{
            Aclaración gradiente red neuronal
        }
    }

    Puede a priori uno confundirse con la notación,  
    pero recordemos que las redes neuronales estaban determinadas por sus parámetros (matrices), luego lo único que se está haciendo es derivar con respecto a tales parámetros.
} 
%Fin nota margen
% Idea  sobre el algoritmo de gradiente descendente 
\marginpar{
    \textcolor{dark_green}{    
        \textbf{
            Idea general del algoritmo gradiente descendente
        }
    }

    Cada iteración se obtendrá una nueva red neuronal con un error menor dentro de los datos de entrenamiento del conjunto.
} 

% Nota margen sobre diferenciabilidad
\normalmarginpar
\setlength{\marginparwidth}{\smallMarginSize}
\marginpar{
    \textcolor{red}{    
        \textbf{
            Consecuencia del requisito de diferenciabilidad 
            de $E(h)$
        }
    }
    $E(h)$ será diferenciable si y sólo si las funciones de activación lo son. 
}


%Fin nota margen
En nuestro caso particular se quiere aproximar la función ideal desconocida $f$ a partir de funciones (redes neuronales) $h \in \rrnnmc$, concretamente se fijará un número $q$ de neuronas en la capa oculta. 
Dada también una función de error diferenciable y que no presente puntos de inflexión
$E: \mathcal{H}_q (\R^d, \R^s) \longrightarrow \R,$
se toma red neuronal cualquiera $h_0 \in \mathcal{H}_q (\R^d, \R^s)$ y 
fijado $\eta \in \R^+$. 

Se define la sucesión 
\begin{equation}\label{eq:descenso-gradiente}
    h_{t+1}  = h_t - \eta \nabla E(h_t).
\end{equation}  

Donde $h_n$ es una sucesión cuyos términos convergen a un mínimo local.
\subsubsection*{Observaciones sobre el algoritmo }

\begin{itemize}
    \item El algoritmo solo encuentra óptimos locales con una dependencia crucial del valor de inicio. 
    \item La convergencia no es segura en un tiempo finito y requiere de criterios de parada. 
    \item Debe de fijarse el número de neuronas en la capa oculta a priori.
    \item Si la función es convexa el mínimo será global.
    \item El parámetro $\eta$ puede ser cualquiera y debe de ser fijado o controlado por el diseñador.  
\end{itemize}


Con el fin de reducir el coste del cálculo del gradiente, 
se utiliza el algoritmo conocido como \textit{backpropagation} que fue publicado en 
1989 en el artículo \cite{backpropagation-Hinton}. 

Denotaremos como $w$ al conjunto de parámetros que determinan el valor de una red neuronal. 

Sea $E_{in}(h_w)$ la función de error habitualmente usada, la cual tomaremos como el error dentro de conjunto de entrenamiento, esto es,  si el conjunto 
de entrenamiento está constituido por $N$ datos de la forma $(x_n, y_n)$ con $x_n$ el vector de entrada y $y_n$ el estado o valor deseado para cualquier $n\in \{1, \ldots, N\}.$
\begin{equation}
    E_{in}(h_w) = \frac{1}{N} \sum^N_{n=1} (h_w(x_n)- y_n)^2. 
\end{equation}
que es una métrica para medir error entre, en nuestro caso  
la red neuronal $h_w$ y los valores de entrenamiento.

Para nuestro caso de una sola capa oculta el resultado sería el siguiente: 
\begin{equation}
    \nabla_w E_{in}(h_w) = \frac{2}{N} \sum^N_{n=1} \nabla_w h_w(x_n)
\end{equation}
y puesto que $\frac{2}{N}$ no es más que una constante que 
puede ser corregida en \refeq{eq:descenso-gradiente} con $\eta$, con el fin de ahorrar coste computacional la 
omitiremos de ahora en adelante. Es decir, podemos suponer que 
nuestra función de error a minimizar es 

\begin{equation}
    E_{in}(h_w) = \frac{1}{2} \sum^N_{n=1} (h_w(x)- y_n)^2. 
\end{equation}

Tengamos presente que hemos definido una red neuronal  $h_w \in \mathcal{H}_q (\R^d, \R^s)$ como
\begin{equation}
    h_w(x) = 
    \sum_{i=1}^q \beta_i 
    \sigma
    \left(  
        \alpha_{0 i} +
        \sum_{j=1}^d \alpha_{j i}x_j
    \right)
\end{equation}
para la cual hemos impuesto que la función de activación $\sigma$ sea diferenciable.

Así pues a la hora de calcular el gradiente tendríamos tres tipos de derivadas parciales, las dependientes de $\beta_i$, 
las de $\alpha_{0 i}$ y las de $\alpha_{j i}$, para cada caso concreto y en virtud de la regla de la cadena, se tiene: 
\begin{itemize}
    \item Derivada parcial del error con respecto a $\beta_i$:
    \begin{align} \label{eq:parcial_beta}
        \frac{\partial E(h)}{\partial \beta_i} 
        =&
        \sum_{n = 1}^N \left(
            \left(h(x_n) - y_n\right)
            \frac{\partial h(x_n)}{\partial \beta_i} 
        \right)
        \\ 
        = &
        \sum_{n = 1}^N \left(
            \left(h(x_n) - y_n\right)
            \sigma
            \left(  
                \alpha_{0 i} +
                \sum_{j=1}^d \alpha_{j i}x_j
            \right)
        \right).
    \end{align}

    \item Derivada parcial del error con respecto a $\alpha_{0 i}$:
    \begin{align} \label{eq:parcial_alpha_cero}
        \frac{\partial E(h)}{\partial \alpha_{0 i}} 
        =&
        \sum_{n = 1}^N \left(
            \left(h(x_n) - y_n\right)
            \frac{\partial h(x_n)}{\partial \alpha_{0 i}} 
        \right)
        \\ 
        = &
        \sum_{n = 1}^N \left(
            \left(h(x_n) - y_n\right)
            \beta_i
            \sigma'
            \left(  
                \alpha_{0 i} +
                \sum_{j=1}^d \alpha_{j i}x_j
            \right)
        \right).
    \end{align}

    \item Derivada parcial del error con respecto a $\alpha_{j i}$:
    
    \begin{align} \label{eq:parcial_alpha_i}
        \frac{\partial E(h)}{\partial \alpha_{j i}} 
        =&
        \sum_{n = 1}^N \left(
            \left(h(x_n) - y_n\right)
            \frac{\partial h(x_n)}{\partial \alpha_{0 i}} 
        \right)
        \\ 
        = &
        \sum_{n = 1}^N \left(
            \left(h(x_n) - y_n\right)
            \beta_i
            \sigma'
            \left(  
                \alpha_{0 i} +
                \sum_{j=1}^d \alpha_{j i}x_j
            \right) x_j
        \right).
    \end{align}
\end{itemize}  

Si el cálculo se hiciera sin tener más consideración alguna que la propia expresión supondría el coste computacional que mostramos en la tabla \ref{tab:coste-computacional-directa}.

% tabla con coste en multiplicación 
\begin{table}[H]
    \begin{center}
    \begin{tabular}{| c | c | c | c | c | c| }
    \hline
    % cabecera
       & Número de parámetros & $+ / -$ & $\times / \div$ & $\sigma$ & $\sigma'$
    \\ \hline
    % Para betas
    (\ref{eq:parcial_beta}) $\frac{\partial E(h)}{\partial \beta_i}$ 
    & $n s$ & $n s (d+1)$ & $n s d$ & $n s$ & 0
    \\
    \hline
    % Para los segos alpha 0i 
    (\ref{eq:parcial_alpha_cero}) $\frac{\partial E(h)}{\partial \alpha_{0 i}}$ 
    & $n$ & $n d$ & $n (d + 1)$ & 0 & $n$
    \\
    \hline
    % Para los segos alpha ji 
    (\ref{eq:parcial_alpha_i}) $\frac{\partial E(h)}{\partial \alpha_{j i}}$ 
    & $n d$ & $n d^2$ & $n d (d + 2)$ & 0 & $n d$
    \\
    \hline
    \end{tabular}
    \caption{Coste computacional de aplicar directamente el  algoritmo de gradiente 
    descendente para actualizar $h \in \mathcal{H}_n(\R^d, \R^s)$}
    \label{tab:coste-computacional-directa}
    \end{center}
\end{table}

Abordar el problema de manera directa es muy ineficiente, ya que como mostramos en la tabla 
\ref{tab:expresiones_repetidas_en_descenso_gradiente}
hay cálculos que se repiten en (\refeq{eq:parcial_beta}), (\refeq{eq:parcial_alpha_cero}) y  
(\refeq{eq:parcial_alpha_i}). 

\begin{table}[H]
    \begin{center}
    \begin{tabular}{| c | c | c | c | c| }
    \hline
    % cabecera
    Expresión  repetida en 
    & $\frac{\partial E(h)}{\partial \beta_i}$ 
    & $\frac{\partial E(h)}{\partial \alpha_{0 i}}$ 
    &$\frac{\partial E(h)}{\partial \alpha_{j i}}$ 
    & Total apariciones 
    \\ \hline
    % primer cálculo repetido 
    $\alpha_{0 i} \sum_{j=1}^d \alpha_{j i}x_j$ 
    & 1 & 1& $d$ & $d+2$
    \\
    % Tercer cálculo repetido 
    $\beta_i \sigma'
    \left(  
     \alpha_{0 i} 
     \sum_{j=1}^d \alpha_{j i}x_j
    \right)$
    & 0 & 1 & $d$ & $d+1$
    \\ \hline
    \end{tabular}
    \caption{Veces que se calcula una misma expresión 
    para el cálculo de gradiente descendente fijado un
     $i$}
    \label{tab:expresiones_repetidas_en_descenso_gradiente}
    \end{center}
\end{table}

A la vista de las repeticiones mostradas en  \ref{tab:expresiones_repetidas_en_descenso_gradiente}
almacenaremos primero en memoria los cálculos parciales. 

Notemos además que las expresiones del tipo 
$\alpha_{0 i} \sum_{j=1}^d \alpha_{j i}x_j$  son las que denotábamos como $sensibilidades$ en el algoritmo de \textit{forward propagation} \ref{algoritmo:evaluar red neuronal}.

Resultando la siguiente implementación del algoritmo de cálculo. 

Primero aplicaremos algoritmo de gradiente descendente 

Sea $W = (A,S,B)$ 
la matrices que definen a una red neuronal $h \in \rrnnsmn$, denotando a estas como: 
\begin{align}
    A &= (a)_{i,j} \text{ con } 1 \leq i \leq n, 1 \leq j \leq d. \\
    S &= (c)_{i} \text{ con } 1 \leq i \leq n. \\
    B &= (b)_{i,j} \text{ con } 1 \leq i \leq s, 1 \leq j \leq n. \\
\end{align}
 $h$ modificará el valor de sus pesos de acorde al algoritmo de gradiente descendente \ref{eq:descenso-gradiente} que viene dado por

\begin{algorithm}[H]
    \caption{Algoritmo gradiente descendente.}
    \hspace*{\algorithmicindent} \textbf{Input}:$h$ red neuronal  y conjunto de entrenamiento \\
    \hspace*{\algorithmicindent} \textbf{Output:} $h$ actualizada de acorde al algoritmo de gradiente descendente. 
    \begin{algorithmic}[1]
        \STATE Debe de calcularse el previamente el $\nabla E(h)$, es decir cada una de la parciales.
        % actualizamos los pesos de a 
        \STATE Actualización de los pesos de $A$ \\  
        \For{
                $i \in \{1,\ldots n\}$
            }{
                \For{
                $j \in \{1,\ldots d\}$
            }{
                \begin{equation}
                    a_{i j} 
                    \gets 
                    \eta 
                    \frac{\partial E(h)}{\partial a_{i j}}
                \end{equation}
            }
        }
         %  Actualizamos los pesos de S               
        \STATE Actualización de los pesos de $S$ \\   
        \For{
                $i \in \{1,\ldots n\}$
            }{
                \begin{equation}
                    c_{i} 
                    \gets 
                    \eta 
                    \frac{\partial E(h)}{\partial c_{i}}
                \end{equation}
        } 
        % actualizamos los pesos de B
        \STATE Actualización de los pesos de $B$ \\ 
        \For{
                $i \in \{1,\ldots s\}$
            }{
                \For{
                $j \in \{1,\ldots d\}$
            }{
                \begin{equation}
                    b_{i j} 
                    \gets 
                    \eta 
                    \frac{\partial E(h)}{\partial b_{i j}}
                \end{equation}
            }
        }
\end{algorithmic}
\end{algorithm}

Notemos la necesidad de una variable $\eta \in \R$ que es prefijada. 

\textcolor{red}{$\eta$ podría ser incluso una vector de pesos que se aplicara de manera distinta a cualquier coeficiente o una función variable de ciertas condiciones. No sé hasta qué punto sería interesante plantearse el uso de algoritmos genéticos para actualizarlo ya que estos carecen de valor teórico. ¿Existe algún resultado de análisis que nos de una cota mejor?}


Procederemos ahora a determinar el cálculo del gradiente, como hemos visto este vienen determinado por la expresión 




