\section{Aprendizaje}  

Se entiende por aprendizaje de una red neuronal como el proceso 
por el cual se determina el valor sus pesos, es decir, lo que en el ejemplo \ref{img:Ejemplo-evaluación-red-neruonal-una-capa} consistía en las matrices $A,S$ y $B$.

%%%%%%%%%%%%%%%%%%% algoritmo de gradiente descendente 

\subsection{Método de gradiente descendente y \textit{backpropagation}} \label{sec:gradiente-descendente}

De acorde a los capítulos uno y dos del libro  \cite{learning-from-data-1-2},
 una vez concretado el problema y sus elementos 
(\ref{sub:componentes_aprendizaje}) es necesario definir un método con 
el que aproximar la función ideal $f,$ para ello introduciremos el algoritmo de gradiente descendente.  

El gradiente descendente es un método iterativo de minimización de funciones diferenciables. 

% Nota sobre el algoritmo de gradiente descendente 
\reversemarginpar
\marginpar{
    \textcolor{dark_green}{    
        \textbf{
            Aclaración gradiente red neuronal
        }
    }

    Puede a priori uno confundirse con la notación,  
    pero recordemos que las redes neuronales estaban determinadas por sus parámetros (matrices), luego lo único que se está haciendo es derivar con respecto a tales parámetros.
} 
%Fin nota margen
% Idea  sobre el algoritmo de gradiente descendente 
\marginpar{
    \textcolor{dark_green}{    
        \textbf{
            Idea general del algoritmo gradiente descendente
        }
    }

    Cada iteración se obtendrá una nueva red neuronal con un error menor dentro de los datos de entrenamiento del conjunto.
} 

% Nota margen sobre diferenciabilidad
\normalmarginpar
\setlength{\marginparwidth}{\smallMarginSize}
\marginpar{
    \textcolor{red}{    
        \textbf{
            Consecuencia del requisito de diferenciabilidad 
            de $E(h)$
        }
    }
    $E(h)$ será diferenciable si y sólo si las funciones de activación lo son. 
}


%Fin nota margen
En nuestro caso particular se quiere aproximar la función ideal desconocida $f$ a partir de funciones (redes neuronales) $h \in \rrnnmc$, concretamente se fijará un número $q$ de neuronas en la capa oculta. 
Dada también una función de error diferenciable y que no presente puntos de inflexión
$E: \mathcal{H}_q (\R^d, \R^s) \longrightarrow \R,$
se toma red neuronal cualquiera $h_0 \in \mathcal{H}_q (\R^d, \R^s)$ y 
fijado $\eta \in \R^+$. 

Se define la sucesión 
\begin{equation}\label{eq:descenso-gradiente}
    h_{t+1}  = h_t - \eta \nabla E(h_t).
\end{equation}  

Donde $h_n$ es una sucesión cuyos términos convergen a un mínimo local.
\subsubsection*{Observaciones sobre el algoritmo }

\begin{itemize}
    \item El algoritmo solo encuentra óptimos locales con una dependencia crucial del valor de inicio. 
    \item La convergencia no es segura en un tiempo finito y requiere de criterios de parada. 
    \item Debe de fijarse el número de neuronas en la capa oculta a priori.
    \item Si la función es convexa el mínimo será global.
    \item El parámetro $\eta$ puede ser cualquiera y debe de ser fijado o controlado por el diseñador.  
\end{itemize}


Con el fin de reducir el coste del cálculo del gradiente, 
se utiliza el algoritmo conocido como \textit{backpropagation} que fue publicado en 
1989 en el artículo \cite{backpropagation-Hinton}. 

Denotaremos como $w$ al conjunto de parámetros que determinan el valor de una red neuronal. 

Sea $E_{in}(h_w)$ la función de error habitualmente usada, la cual tomaremos como el error dentro de conjunto de entrenamiento, esto es,  si el conjunto 
de entrenamiento está constituido por $N$ datos de la forma $(x_n, y_n)$ con $x_n$ el vector de entrada y $y_n$ el estado o valor deseado para cualquier $n\in \{1, \ldots, N\}.$
\begin{equation}
    E_{in}(h_w) = \frac{1}{N} \sum^N_{n=1} (h_w(x)- y_n)^2. 
\end{equation}
que es una métrica para medir error entre, en nuestro caso  
la red neuronal $h_w$ y los valores de entrenamiento.

Para nuestro caso de una sola capa oculta el resultado sería el siguiente: 
\begin{equation}
    \nabla_w E_{in}(h) = \frac{2}{N} \nabla_w h_w(x)
\end{equation}
y puesto que $\frac{2}{N}$ no es más que una constante que 
puede ser corregida en \refeq{eq:descenso-gradiente} con $\eta$ con el fin de ahorrar coste computacional la 
omitiremos de ahora en adelante. Es decir, podemos suponer que 
nuestra función de error a minimizar es 

\begin{equation}
    E_{in}(h) = \frac{1}{2} \sum^N_{n=1} (h_w(x)- y_n)^2. 
\end{equation}

Tengamos presente que hemos definido una red neuronal  $h_w \in \mathcal{H}_q (\R^d, \R^s)$ como
\begin{equation}
    h_w(x) = 
    \sum_{i=1}^q \beta_i 
    \sigma
    \left(  
        \alpha_{0 i} +
        \sum_{j=1}^d \alpha_{j i}x_j
    \right)
\end{equation}
para la cual hemos impuesto que la función de activación $\sigma$ sea diferenciable.

Así pues a la hora de calcular el gradiente tendríamos tres tipos de derivadas parciales, las dependientes de $\beta_i$, 
las de $\alpha_{0 i}$ y las de $\alpha_{j i}$, para cada caso concreto y en virtud de la regla de la cadena, se tiene: 
\begin{itemize}
    \item Derivada parcial del error con respecto a $\beta_i$:
    \begin{align} \label{eq:parcial_beta}
        \frac{\partial E(h)}{\partial \beta_i} 
        =
        \frac{\partial h(x)}{\partial \beta_i} 
        = 
        \sigma
    \left(  
        \alpha_{0 i} +
        \sum_{j=1}^d \alpha_{j i}x_j
    \right).
    \end{align}

    \item Derivada parcial del error con respecto a $\alpha_{0 i}$:
    \begin{align} \label{eq:parcial_alpha_cero}
        \frac{\partial E(h)}{\partial \alpha_{0 i}} 
        =
        \frac{\partial h(x)}{\partial \alpha_{0 i}} 
        = 
        \beta_i \sigma'
    \left(  
        \alpha_{0 i} +
        \sum_{j=1}^d \alpha_{j i}x_j
    \right).
    \end{align}

    \item Derivada parcial del error con respecto a $\alpha_{j i}$:
    
    \begin{align} \label{eq:parcial_alpha_i}
        \frac{\partial E(h)}{\partial \alpha_{j i}} 
        =
        \frac{\partial h(x))}{\partial \alpha_{j i}} 
        = 
        \beta_i \sigma'
    \left(  
        \alpha_{0 i} +
        \sum_{j=1}^d \alpha_{j i}x_j
    \right) x_j.
    \end{align}
\end{itemize}  

Si el cálculo se hiciera sin tener más consideración alguna que la propia expresión supondría un coste computacional de: 

% tabla con coste en multiplicación 


\begin{table}[h]
    \begin{center}
    \begin{tabular}{| c | c | c | c | c | c| }
    \hline
    % cabecera
       & Número de parámetros & $+ / -$ & $\times / \div$ & $\sigma$ & $\sigma'$
    \\ \hline
    % Para betas
    (\ref{eq:parcial_beta}) $\frac{\partial E(h)}{\partial \beta_i}$ 
    & $n s$ & $n s (d+1)$ & $n s d$ & $n s$ & 0
    \\
    \hline
    (\ref{eq:parcial_alpha_cero}) $\frac{\partial E(h)}{\partial \alpha_{0 i}}$ 
    & $n$ & $n (d+1)$ & $n s d$ & $n s$ & 0
    \\
    \hline
    % Para los segos alpha 0i 
    \end{tabular}
    \caption{Coste computacional aplicar para el cálculo directo para actualizar $h \in \mathcal{H}_n(\R^d, \R^s)$}
    \label{tab:coste-computacional-directa}
    \end{center}
\end{table}

A la vista de estas expresiones debemos de definir un algoritmo que busque ahorro en memoria y en coste computacional.

Para el coste computacional notaremos que hay cálculos que se repiten en (\refeq{eq:parcial_beta}), (\refeq{eq:parcial_alpha_cero}) y  
(\refeq{eq:parcial_alpha_i}). 

\begin{table}[h]
    \begin{center}
    \begin{tabular}{| c | c | c | c | c| }
    \hline
    % cabecera
    Apariciones de cierta expresión en 
    & $\frac{\partial E(h)}{\partial \beta_i}$ 
    & $\frac{\partial E(h)}{\partial \alpha_{0 i}}$ 
    &$\frac{\partial E(h)}{\partial \alpha_{j i}}$ 
    & Total apariciones 
    \\ \hline
    % primer cálculo repetido 
    $\mathfrak{S} =  \alpha_{0 i} \sum_{j=1}^d \alpha_{j i}x_j$ 
    & 1 & 1& $d$ & $d+2$
    \\
    % Segundo cálculo repetido 
    $\mathfrak{D} = \sigma'
    \left(  
        \mathfrak{S}
    \right) = \sigma'
    \left(  
     \alpha_{0 i} 
     \sum_{j=1}^d \alpha_{j i}x_j
    \right)$
    & 0 & 1 & $d$  & $d+1$
    \\
    % Tercer cálculo repetido 
    $\beta_i \mathfrak{D} = \beta_i \sigma'
    \left(  
     \alpha_{0 i} 
     \sum_{j=1}^d \alpha_{j i}x_j
    \right)$
    & 0 & 1 & $d$ & $d+1$
    \\ \hline
    \end{tabular}
    \caption{Veces que se calcula cierta expresión fijado un $i$}
    \label{tab:expresiones_repetidas_en_descenso_gradiente}
    \end{center}
\end{table}

A la vista de los resultados expuesto en la tabla \ref{tab:expresiones_repetidas_en_descenso_gradiente}, exponemos la siguiente relación coste computacional coste en memoria

