%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Experimentación con ALGORITMO INICIALIZACIÓN DE PESOS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

En la siguiente sección trataremos sobre la bondad del algoritmo expuesto

\section{Contraste de hipótesis con inicialización aleatoria} 
\label{ch07:experimento-1} 

Las preguntas a resolver son ¿mejora nuestro algoritmo? ¿Cuánto mejora?

La primera observación  es que como
hemos observado en el modelado de una red neuronal 
en la sección \ref{ch05:construction-evaluation-nnnn}
una red neuronal depende de varios parámetros:
la dimensión de entrada $d$, el número de neuronas en la capa oculta $n$, la dimensión de salida $s$ 
y la funciones de activación de cada neurona.  

Por simplicidad fijaremos una función de activación. 


\subsection{Descripción experimento}

El experimento costa de los siguientes pasos: 

\begin{enumerate}
% Paso 0: Selección de data sets 
\item Dado un conjunto de datos de entrenamiento $\D$  se separará el conjunto en:
\begin{itemize}
    \item $\D_i$ \textbf{Conjunto de 
    datos de inicialización.} Debe de ser mayor que 
    $n$ y lo suficientemente grande para que el algoritmo diseñado funcione correctamente. 

    \item $\D_t$ \textbf{Conjunto de 
    datos de test.} Se utilizarán para el cálculo del error. 
\end{itemize} 

En particular hemos utilizado el conjunto de datos \href{https://archive.ics.uci.edu/ml/datasets/Airfoil+Self-Noise
    }{
        Airfoil Self-Noise} obtenido del repositorio de datos libres para aprendizaje automático \href{https://archive.ics.uci.edu/ml/datasets.php}{UCI}. 
El conjunto elegido se corresponde a un problema de regresión con $1503$ instancias y $6$ atributos. 
Para la implementación realizada podría utilizarse cualquier otra que provenga de un problema de regresión. 

Notemos que $d$ viene determinado por el número de atributos, 
$s$ será uno ya que estamos frente a un problema 
de regresión de variable real y $n$ vendrá dado como $n = \lfloor \alpha |\mathcal{D}_i| \rfloor$ con $\alpha \in (0,1)$; concretamente, en virtud de la observaciones mostrada en la sección \ref{section:inicializar_pesos} de que la probabilidad de que un dato no pueda ser utilizado para el algoritmo es nula; suponer que el $90\%$ de los datos sí serán válidos es una estimación lo suficientemente precavida como para que el algoritmo no \textit{falle}, es decir haremos    $\alpha = 0.9$. 

% Paso 1: Construcción 
\item Fijados $n, d$ y $s$ se generarán dos redes neuronales: 

\begin{itemize}
    \item Una inicializada de manera aleatoria con valores dentro de un rango de valores. 
    
    \item  Otra inicializada con nuestro algoritmo, se medirá el $t_i$ tiempo y el error $\varepsilon_i$ en  $\D_t$. 
\end{itemize}

% Paso 2: Evaluación del error
\item Con los datos de entrenamiento $D_i$ y el algoritmo de aprendizaje de \textit{Backpropagation}se entrenará la neuronal inicializada aleatoriamente hasta que iguale o supere el error $\varepsilon_i$. Además puesto que puede darse el caso de quedar estancados en un mínimo local  o que oscile entorno a un mínimo (ver propiedades del gradiente descendente \ref{ch05:gradiente-descentente})
superior al error encontrado con el algoritmo de inicialización de pesos, se ha añadido también como criterio de parada el que error se estanque o empeore durante 5 iteraciones consecutivas. 
Se medirá el tiempo que necesita hasta su fin $t_b$ y el error en entrenamiento y test. 

Los tiempos $t_i$ y $t_b$ serán los que compararemos. 
\end{enumerate}

Los pasos 2 y 3 se repetirán tantas veces como 
muestras se desee tomar. 

\subsection{Contraste de hipótesis}

Se desea comparar si las diferencias en los tiempos observados efectivamente son notables: 

Para ello se realizará un test de Wilcoxon, con las siguientes hipótesis

\begin{itemize}
    \item $H_0$: La mediana de las diferencia de cada par de muestras es $0$. 
    \item $H_a$: La mediana de las diferencia entre cada par de muestras es diferente de cero. 
\end{itemize}

La utilidad de este test es que si rechaza la hipótesis la hipótesis nula sabremos que con un $95 \%$ de certeza tendrán medianas diferentes, es decir, \textbf{existe una 
diferencia en los errores}. En caso de que no se rechace no podremos afirmar nada.
Puede encontrar la implementación en el repositorio del
 proyecto \footnote{En el directorio de experimentos 
 de \url{https://github.com/BlancaCC/TFG-Estudio-de-las-redes-neuronales}.}.

\subsection{Requisitos técnicos}  

A la vista de todo el proceso es descrito surgen las siguientes necesidades técnicas que deberemos de implementar:  

\subsubsection{Lectura y tratamiento de los datos}

Se necesita ser capaces de leer los datos desde los ficheros descargados, es decir, ser capaces de transformar el formato \textit{.dat} en un \textit{.csv}. 
Además, es necesario un tratamiento previo de los datos: 
\begin{itemize}
    \item Comprobación de que no hay valores nulos o perdidos. 
    \item Normalización de los datos. 
\end{itemize}


\subsubsection{Capacidad de crear una red neuronal aleatoria}  

Deberá de crearse una red neuronal con entradas dentro de un rango $[a,b]$ con $a < b$ reales,
que tenga una entrada de tamaño $d$,
$n$ neuronas en la capa oculta y
una dimensión de salida $d$.

\subsubsection{Implementación del algoritmo de inicialización}

Deberá de implementarse del algoritmo  \ref{algo:algoritmo-iniciar-pesos} con todos los requisitos y atributos que ahí se describe.  

\subsubsection{Función para medir el error}

Deberá implementarse una función para medir el
 error, puesto que nos hayamos frente a un problema de regresión utilizaremos el error cuadrático medio. 

\subsubsection{Forma de evaluar las redes neuronales}  

Dado una red neuronal, una función de evaluación y un datos ser capaz de aplicar el algoritmo de \textit{forward propagation} descrito en \ref{algoritmo:evaluar red neuronal}.

\subsubsection{Implementación del aprendizaje de una red neuronal} 
% Nota en el margen sobre la derivada
\marginpar{\maginLetterSize
    \iconoAclaraciones \textcolor{dark_green}{     
        \textbf{
            Qué es una derivada débil.
        }
    }
    Es una generalización de las derivadas para funciones del espacio $L_p$, esto nos permite
    definir derivadas aunque no lo sea en algunos puntos (recodemos que demostremos el teorema de aproximación universal para estos espacios en la sección \ref{ch04:espacios-Lp}).   
}
Se implementará el algoritmo propio de aprendizaje basado en \textit{Backpropagation} y ya optimizado 
que describimos en los algoritmos \ref{algoritmo:gradiente-descendente} y \ref{algoritmo:calculo-gradiente}.
Cabe destacar que para este algoritmo es necesario la derivada de las funciones de las funciones de activación. Se ha implementado la derivada débil de ellas. 

\subsubsection{Implementación del experimento} 
Deberá de implementarse una función que realice el 
experimento tal cual hemos descrito en \ref{ch07:experimento-1}.

% Se ha eliminado el contenido de aquí anterior porque eran notas en sucio