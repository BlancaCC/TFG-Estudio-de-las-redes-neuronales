% !TeX root = ../../tfg.tex
% !TeX encoding = utf8
%
%*******************************************************
% Contenido del artículo 1: Definiciones primeras
%*******************************************************

\section{Definiciones primeras}\label{ch:articulo:sec:defincionesPrimeras}  

Comenzaremos presentando definiciones básicas sobre redes neuronales. 


\begin{definicion}[Función de activación ] \label{def:funcion_activacion_articulo}
    Una función  $\psi: \R \longrightarrow [0,1]$ es una \textbf{ función de activación} si  cumple las siguientes propiedades:
    \begin{enumerate}[label=(\roman*)]
        \item Es no decreciente.
        \item $\lim _{x \rightarrow \infty} \psi(x) = 1
        $.
        \item $\lim _{x \rightarrow -\infty} \psi(x) = 0$.
    \end{enumerate}  
   
    Ejemplos comunes de funciones de activación son

    %%% Nota sobre funciones activación más democráticas que otras
    \marginpar{\maginLetterSize
         \iconoProfundizar \textcolor{blue}{    
        \textbf{Observación sobre la idoneidad de cada función activación:}
    }
    Se probará la convergencia de las redes neuronales independientemente de la función de activación seleccionada. Cabe entonces la pregunta
    ¿Existen funciones de activación más democráticas que otras? 
    Se discutirá esta pregunta como hipótesis de optimización \ref{hypothesis:activation-function}.
    }

    % Imágenes de la función indicadora 
    \begin{figure}[h]
        \centering
        \begin{subfigure}[t]{0.47\textwidth}
            \centering
            \includegraphics[width=\textwidth]{
                articulo_rrnn_aproximadores_universales/función_indicadora_l_0.png}
            \caption{Función indicadora $\lambda_0 = 0$}  
            \label{fig:función_indicadora}
        \end{subfigure}
        \hfill
        \begin{subfigure}[t]{0.47\textwidth}  
            \centering 
            \includegraphics[width=\textwidth]{articulo_rrnn_aproximadores_universales/función_umbral_lineal.png
            }
            \caption{Función umbral $w=(2)$, $t=1$}    
            \label{fig:función_umbral_lineal}
        \end{subfigure}
        \begin{subfigure}[t]{0.47\textwidth}   
            \centering 
            \includegraphics[width=\textwidth]{articulo_rrnn_aproximadores_universales/función_rampa.png}
            \caption{Función rampa} 
            \label{fig:funciones_rampa}
        \end{subfigure}
        \hfill
        \begin{subfigure}[t]{0.47\textwidth}   
            \centering 
            \includegraphics[width=\textwidth]{articulo_rrnn_aproximadores_universales/cosineSquasherSinTitulo.png}
            \caption{\textit{Cosine Squasher}}   
            \label{fig:cosine_squasher}
        \end{subfigure}
        \caption{Ejemplos de funciones de activación} 
        \label{fig:EjemplosFunciónActivación}
    \end{figure}

    \begin{itemize}
        \item \textbf{Funciones umbral} \ref{fig:función_umbral_lineal}:
        Una función umbral, es una función booleana monótona $\psi_w: \{0,1\}^n \longleftarrow \{0,1\},$ 
        donde para $w \in \R^n$, $t \in \R$ fijos se
        satisface que 
        \begin{equation}
            \psi_w(x) = \left\{
                \begin{array}{lcc}
                    1, &   si  & w \cdot x \geq t \\
                    0, &  si & w \cdot x < t\\
                    \end{array}
            \right.
        \end{equation}
        
        \item \textbf{Funciones indicadoras} \ref{fig:función_indicadora}: $\psi(\lambda) = 1_{\{\lambda > \lambda_0\}}$ con $\lambda_0 \in \R$. 
        \item \textbf{Función rampa} \ref{fig:funciones_rampa}: $\psi(\lambda)  = \lambda 1_{\{0 \leq \lambda \leq  1\}} + 1_{\{\lambda > 1\}}.$
    
        \item \textbf{La función \textit{cosine squasher}} de Gallant and White 
        \ref{fig:cosine_squasher} (1988) \cite{Gallant88thereexists}. 
        \begin{equation*}
    \psi(\lambda )= \left(1 + \cos\left(\lambda + 3 \frac{\pi}{2} \right) \frac{1}{2}\right) 
     1_{\{\frac{-\pi}{2} \leq \lambda \leq  \frac{\pi}{2}\}}
     +
     1_{\{ \frac{\pi}{2} < \lambda \}}.
    \end{equation*}
    \end{itemize}

   Notemos que así definidas las funciones de activación son medibles, ya que la imagen inversa de un abierto de $[0,1]$ siempre será un conjunto medible de  $\R$  (capítulo 7  página 77 \cite{nla.cat-vn1819421}).
    
    % Nota margen sobre que abstrae esta estructura de red neuronal
    \marginpar{\maginLetterSize
        \iconoAclaraciones \textcolor{dark_green}{     
        \textbf{Idea tras la definición de $\pmc$.}
        }
    Nótese que de acorde a nuestra definición  
    \textcolor{red}{TODO añadir referencia}
    lo que se ha definido es la clase de las redes 
    neuronales de una capa oculta y salida de una dimensión.
    Donde cada sumando representa una neurona de la capa oculta.
    }
    %%% fin nota

    Cabe destacar que la definición tomada es la propuesta en \cite{HORNIK1989359} y que existen
    otras posibles definiciones menos restrictivas con las que también se ha probado la convergencia universal,
    por ejemplo podrían aceptarse funciones de activación no continuas \cite{FUNAHASHI1989183},  
    o como 
    en \cite{DBLP:journals/corr/SonodaM15} con funciones de activación no polinómicas no acotadas. 
    \textcolor{red}{A priori no debería de ser equivalentes entre ellas y será necesario un estudio más 
    profundo para establecer \textit{cuáles son las más democráticas}}
    %TODO añadir sección 

\end{definicion}



Para cualquier natural $d$ mayor que cero  denotaremos por $\afines$ al conjunto de todas 
las \textbf{funciones afines} de $\R^d$ a $\R$. Es decir el conjunto de funciones de la forma 
$A(x) = w \cdot x + b$ donde $x$ y $w$ son vectores de $\R^d$,  $b \in \R$ es un escalar
 y $\cdot$ representa el producto 
usual de escalares.  
    
En este contexto, $x$ corresponde al vector entrada de la red neuronal, $w$ los pesos de la red
que se multiplicarán con $x$ en la capa intermedia y $b$ el sesgo. 

  % Nota margen sobre Idea intuitiva de la definición 
  \marginpar{\maginLetterSize
    \iconoAclaraciones \textcolor{dark_green}{     
   \textbf{Motivación de la definición de $\pmcg$}}.
    
   En un principio será más fácil demostrar que con funciones de esta clase seremos capaz de aproximar cualquier función continua.
   De esta manera este conjunto actuará de nexo de unión entre las funciones continuas y las redes neuronales facilitando las demostraciones. De ahora en adelante nos referiremos a este conjunto como al \textbf{de anillo de aproximación} (como curiosidad, el nombre proviene a que tiene estructura de anillo y que se utilizará para aproximar funciones continuas).
   }



\begin{definicion} [Formalización de una red neuronal de una capa oculta y salida real]
    Para cualquier función Borel medible $G$, definida de $\R$ a $\R$ y cualquier natural positivo
    $d \in \N$ se define a la clase de funciones $\pmc$ como 

    \begin{equation}
        \begin{split}
        \pmc = 
        \{ 
            & f: \R ^d \longrightarrow \R / \quad
            f(x)=\sum_{j = 1} ^q (
            \beta_j G(A_{j}(x)), \\
            & x  \in \R ^d, \beta_j \in \R, A_{j}\in \afines,q \in \N
            )
        \}.
        \end{split}
    \end{equation}

    Conforme avancen los resultado teórico veremos que $\pmc$ 
    no depende de la función $G$ seleccionada, así pues tras enunciar tales resultados nos referiremos sin ambigüedad tal conjunto como $\rrnn$.
\end{definicion}

Definiremos a continuación una familia de funciones más generales que $\pmc$ con la intención de que actúe como nexo de unión entre la clase de funciones continuas y las redes neuronales de una capa facilitándonos con ello la prueba de los resultados. La familia que introduciremos solo tiene 
una utilidad teórica, es decir no tendrá ninguna relevancia a nivel práctico en cuanto a implementaciones.
   

\begin{definicion} [Anillo de aproximación de redes neuronales]\label{def:articulo_abstracción_rrnn}
    
    \begin{equation} 
        \begin{split}
        \sum \prod^d(G) = \{ 
        &f: \R^r \longrightarrow \R / \quad
        f(x) = \sum_{j = 1} ^q  \beta_j \prod_{k=1}^{l_j}
        G(A_{jk}(x)), \\
        &x  \in \R^d, \beta_j \in \R, A_{jk}\in \afines; l_j,q \in \N
        )
        \}.
    \end{split}
    \end{equation}  

 
    Notemos que $\pmc$ se recupera en el caso particular en el que $l_j = 1$ para todo $j$.
    Los elementos de $\pmcg$ son combinaciones lineales de productos finitos de neuronas. 

\end{definicion}


\subsection{ Reflexión sobre la relevancia de la función de activación}  

\textcolor{red}{Este párrafo es redundante con el de la introducción, habría que ver cómo casarlos}
La función de activación $G$ es clave en el proceso de aprendizaje.
Por una parte nótese que como $\afines$ es el espacio de funciones afines, lo que se está haciendo es 
aproximar una función medible a partir de combinaciones lineales de \textit{rectas} evaluadas mediante $G$. 
 
\begin{figure}[h!]
    \includegraphics[width=\textwidth]{articulo_rrnn_aproximadores_universales/ejemploAproximaciónCurvasPorRectas.jpeg}
    \caption{Ejemplo de curva aproximada por un perceptrón multicapa \cite{alma991008058419704990}. El interior de la curva da lugar a la categoría $+$ y el exterior a otra, la $-$.}
    \label{img:def_esenciales_ejemplo_curva_aproximada_percentrón_multicapa}
\end{figure}

Se probará la convergencia de las redes neuronales independientemente de la función de activación seleccionada. Cabe entonces la pregunta
¿Existen funciones de activación más democráticas que otras? 
Se discutirá esta pregunta como hipótesis de optimización \ref{hypothesis:activation-function}.

Por otra parte, la función de activación acota la imagen de una aplicación afín, esta limitación 
es de total relevancia ya que permite una interpretación previamente convenida. 
Decimos por ende que es la causante del \textit{aprendizaje}.     

  %%% Nota margen sobre función medible 
  \marginpar{\maginLetterSize
    \iconoAclaraciones \textcolor{dark_green}{     
        \textbf{
            Aplicación práctica aprendizaje automático y 
            relación con las funciones medible.
        }
    }
    \textbf{A nivel práctico se tiene un conjunto de datos
    para los cuales queremos extraer un patrón} que nos permita 
    predecir la naturaleza de datos nuevos. Es por ello necesario
    suponer que estos datos están regidos por alguna regla, la cual 
    puede ser todo lo extraña posible pero que toma valores 
    que pueden ser observables y cuantificables en la mayoría de los casos, estos comportamientos son formalizados
     matemáticamente con \textbf{funciones medibles}.
}
Por si el comentario no ha resultado claro procedamos a dar un ejemplo:   
Supongamos que nos hallamos frente a un problema de clasificación de dos clases y que la función de activación
tomada es una función umbral que toma valores cero o uno. Define por tanto esta función una separación de clases. 
De otra manera, de solo existir la función afín sin una transformación de la salida, el codominio serían 
todos los número reales donde a priori no se explicita una asignación de clase.  

Introducimos a continuación la notación de los conjuntos de funciones que seremos capaces de aproximar.  

Denotamos por  $\fC$ al conjunto de funciones continuas con dominio en $\R^d$ y codominio $\R$,
por  $\fM$ al conjunto de todas las funciones Borel medible de $\R^d$ a $\R$. 
y por $B^d$ a la $\sigma$-álgebra de Borel en $\R ^d$. 

En lo que respecta a definiciones anteriores, $\pmc$ y $\pmcg$ pertenecen a 
$\fM$ para cualquier función Borel-medible $G$. Si $G$ es continua entonces 
$\pmc$ y $\pmcg$ pertenecen a $\fC$. Tengamos presente que $\fC$ es un subconjunto
de $\fM$.  

De ahora en adelante nos referiremos a Borel-medible como medible. 
  

\subsection{ Reflexión sobre el tipo de funciones que se pueden aproximar}

La existencia de funciones no medibles manifiesta una limitación
de la formalización actual de las redes neuronales que plantea las siguientes 
preguntas: 
\begin{enumerate}
    \item ¿Supone la existencia de este tipo de funciones una verdadera limitación a nivel práctico?
    \item ¿Se podría construir alguna arquitectura que sí que las aproximara?
\end{enumerate}  

Continuando con el hilo de la segunda cuestión, si se carece de un espacio vectorial, 
de una medida,  ¿Cómo se podría construir una sucesión de funciones que se aproxime?
Quizás habría que buscar características más intrínsecas del problema en cuestión, 
razonamientos topológicos.

\begin{definicion} [Subconjunto denso]
    % Nota margen de denso
    \reversemarginpar 
    \setlength{\marginparwidth}{\smallMarginSize}
    \marginpar{\maginLetterSize
        \iconoAclaraciones \textcolor{dark_green}{ 
            \textbf{Idea intuitiva conjunto denso.}
        }
        Si $S$ es denso en $T$, 
        se está está diciendo que \textbf{los elementos de $S$ son capaces de aproximar cualquier elemento de $T$
        con la precisión que se desee}. 
    }
    \normalmarginpar
    Dado un subconjunto $S$ de un espacio métrico $(X, \rho)$, se dice que $S$ es denso por la distancia $\rho$
    en subconjunto $T$ si para todo $\epsilon$ positivo y cualquier $t \in T$ existe un $s \in S$ tal 
    que $\rho(s,t) \leq \epsilon$. 
\end{definicion}

Un ejemplo habitual sería en el espacio métrico $(\R, |\cdot|)$ con $|\cdot|$ el valor absoluto, el subconjunto 
$T = \R$ y $S$ los números irracionales, $S = \R \setminus \Q$. 


\begin{definicion} 
    Un subconjunto $S$ de $\fC$ se dice que es \textbf{uniformemente denso para compactos} en  $\fC$
    si para cada subconjunto compacto $K \subset \R^d$ se tiene que $S_K$ es denso según $\rho_K$ en $\fC$
    donde $\rho_K$ está definida como sigue.
    Para cualquier $f,g \in \fC$ 
    \begin{equation}
        \rho _ K (f,g) = \sup_{x \in K} |f(x) - g(x)|.
    \end{equation}

    % Nota intuitiva de compacto
    \marginpar{\maginLetterSize
        \iconoAclaraciones \textcolor{dark_green}{ 
          \textbf{Noción intuitiva de compacto}
        }
        Al trabajar con números reales, un espacio es compacto si es cerrado y acotado, lo que a nivel práctico significa que los
        \textbf{datos de entrada se encuentran dentro de un rango concreto}. 
      }

      % Nota intuitiva de uniformemente denso
      \marginpar{\maginLetterSize
        \iconoAclaraciones \textcolor{dark_green}{ 
          \textbf{Noción intuitiva de uniformemente denso para compactos }
        }
          lo que indica es que \textit{controlamos} \textbf{cuánto de cerca
          están dos funciones sea cual sea cualquier punto del compacto en que evaluemos} es decir, podríamos afirmar que para una red neuronal que tome valores por ejemplo en $[0,1]^r$, se puede saber que su error es menor que $\epsilon \in\R^+$ independientemente de la entrada.
      }
      
\end{definicion}

\begin{definicion}
    Una serie de funciones $\{f_n\}$ \textbf{converge uniformemente a una función $f$ sobre compactos} si para 
    cada  conjunto compacto $K \subset \R^d$  se cumple que
    \begin{equation}
        \rho_k (f_n, f) \longrightarrow 0 \text{ cuando } n \longrightarrow \infty.
    \end{equation} 
\end{definicion}

