\relax 
\providecommand\hyper@newdestlabel[2]{}
\citation{mcculloch1943logical}
\citation{rosenblatt1958perceptron}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Aprendizaje profundo}{21}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lol}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{ch:dl}{{2}{21}{Aprendizaje profundo}{chapter.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Origen}{21}{section.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}Neurona de McCulloch-Pitts}{21}{subsection.2.1.1}\protected@file@percent }
\@writefile{brf}{\backcite{mcculloch1943logical}{{21}{2.1.1}{subsection.2.1.1}}}
\newlabel{def:neuron-mp}{{2.1}{21}{Neurona de McCulloch-Pitts}{definicion.2.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}Perceptrón}{21}{subsection.2.1.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Neurona McCulloch-Pitts con entrada $\textbf  {x}$ y umbral $\theta $.}}{22}{figure.2.1}\protected@file@percent }
\newlabel{fig:neuron-mp}{{2.1}{22}{Neurona McCulloch-Pitts con entrada $\textbf {x}$ y umbral $\theta $}{figure.2.1}{}}
\@writefile{brf}{\backcite{rosenblatt1958perceptron}{{22}{2.1.2}{subsection.2.1.2}}}
\newlabel{def:perceptron}{{2.2}{22}{Perceptrón}{definicion.2.2}{}}
\citation{wikipedia2017separ}
\citation{novikoff1963convergence}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Perceptrón con entrada $\textbf  {x}$, pesos $\textbf  {w}$ y umbral $\theta $.}}{23}{figure.2.2}\protected@file@percent }
\newlabel{fig:perceptron}{{2.2}{23}{Perceptrón con entrada $\textbf {x}$, pesos $\textbf {w}$ y umbral $\theta $}{figure.2.2}{}}
\newlabel{def:clasbin}{{2.3}{23}{Problema de clasificación binario}{definicion.2.3}{}}
\@writefile{brf}{\backcite{wikipedia2017separ}{{23}{2.1.2}{definicion.2.3}}}
\@writefile{brf}{\backcite{novikoff1963convergence}{{23}{2.1.2}{figure.2.3}}}
\citation{abu2012learning}
\citation{abu2012learning}
\citation{abu2012learning}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Ejemplo de perceptrón separando linealmente dos conjuntos de datos. Al separar es posible asignar a cada región una etiqueta, siendo equivalente separar a clasificar.}}{24}{figure.2.3}\protected@file@percent }
\newlabel{fig:perceptron-ej}{{2.3}{24}{Ejemplo de perceptrón separando linealmente dos conjuntos de datos. Al separar es posible asignar a cada región una etiqueta, siendo equivalente separar a clasificar}{figure.2.3}{}}
\newlabel{eq:percep-rule}{{2.1.2}{24}{Perceptrón}{figure.2.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.3}Perceptrón MultiCapa}{24}{subsection.2.1.3}\protected@file@percent }
\@writefile{brf}{\backcite{abu2012learning}{{24}{2.1.3}{subsection.2.1.3}}}
\@writefile{brf}{\backcite{abu2012learning}{{24}{2.1.3}{subsection.2.1.3}}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Esta $f$ no se puede aprender con un solo perceptrón.}}{24}{figure.2.4}\protected@file@percent }
\newlabel{fig:xor}{{2.4}{24}{Esta $f$ no se puede aprender con un solo perceptrón}{figure.2.4}{}}
\citation{abu2012learning}
\citation{abu2012learning}
\citation{abu2012learning}
\@writefile{brf}{\backcite{abu2012learning}{{25}{2.1.3}{figure.2.4}}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces Cada perceptrón aprende un hiperplano distinto.}}{25}{figure.2.5}\protected@file@percent }
\newlabel{fig:dos-percep}{{2.5}{25}{Cada perceptrón aprende un hiperplano distinto}{figure.2.5}{}}
\@writefile{brf}{\backcite{abu2012learning}{{25}{2.1.3}{figure.2.5}}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces Funciones $AND$ y $OR$ como perceptrones.}}{25}{figure.2.6}\protected@file@percent }
\newlabel{fig:and-or}{{2.6}{25}{Funciones $AND$ y $OR$ como perceptrones}{figure.2.6}{}}
\@writefile{brf}{\backcite{abu2012learning}{{25}{2.1.3}{figure.2.6}}}
\citation{abu2012learning}
\citation{rumelhart1985learning}
\@writefile{lof}{\contentsline {figure}{\numberline {2.7}{\ignorespaces Perceptrón que implementa $AND(h_1\overline  {h_2}, \overline  {h_1}h_2)$.}}{26}{figure.2.7}\protected@file@percent }
\newlabel{fig:or1}{{2.7}{26}{Perceptrón que implementa $AND(h_1\overline {h_2}, \overline {h_1}h_2)$}{figure.2.7}{}}
\@writefile{brf}{\backcite{abu2012learning}{{26}{2.1.3}{figure.2.7}}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.8}{\ignorespaces Añadimos dos perceptrones $AND(h_1, \overline  {h_2})$ (en azul) y $AND(\overline  {h_1}, h_2)$ (en rojo).}}{26}{figure.2.8}\protected@file@percent }
\newlabel{fig:and2}{{2.8}{26}{Añadimos dos perceptrones $AND(h_1, \overline {h_2})$ (en azul) y $AND(\overline {h_1}, h_2)$ (en rojo)}{figure.2.8}{}}
\@writefile{brf}{\backcite{abu2012learning}{{26}{2.1.3}{figure.2.8}}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.9}{\ignorespaces Los dos perceptrones iniciales $h_1$ (azul) y $h_2$ (rojo).}}{26}{figure.2.9}\protected@file@percent }
\newlabel{fig:mlp}{{2.9}{26}{Los dos perceptrones iniciales $h_1$ (azul) y $h_2$ (rojo)}{figure.2.9}{}}
\@writefile{brf}{\backcite{rumelhart1985learning}{{26}{2.1.3}{figure.2.9}}}
\citation{abu2012learning}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Redes Neuronales Hacia Adelante}{27}{section.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Descripción}{27}{subsection.2.2.1}\protected@file@percent }
\@writefile{brf}{\backcite{abu2012learning}{{27}{2.2.1}{subsection.2.2.1}}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.10}{\ignorespaces Estructura genérica de una FFNN con $L$ capas, dimensiones $d^{(\ell )}$, entrada $\textbf  {x}$, salida $\textbf  {y}$ y funciones de activación $\sigma $.}}{27}{figure.2.10}\protected@file@percent }
\newlabel{fig:ffnn}{{2.10}{27}{Estructura genérica de una FFNN con $L$ capas, dimensiones $d^{(\ell )}$, entrada $\textbf {x}$, salida $\textbf {y}$ y funciones de activación $\sigma $}{figure.2.10}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Estructura}{27}{subsection.2.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.2.1}Arquitectura}{27}{subsubsection.2.2.2.1}\protected@file@percent }
\citation{moujahid2016activations}
\newlabel{eq:pesos}{{2.2.2.1}{28}{Arquitectura}{subsubsection.2.2.2.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.2.2}Función de activación}{28}{subsubsection.2.2.2.2}\protected@file@percent }
\@writefile{brf}{\backcite{moujahid2016activations}{{28}{2.2.2.2}{subsubsection.2.2.2.2}}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.11}{\ignorespaces Funciones de activación.}}{28}{figure.2.11}\protected@file@percent }
\newlabel{fig:activations}{{2.11}{28}{Funciones de activación}{figure.2.11}{}}
\citation{abu2012learning}
\newlabel{def:softmax}{{2.4}{29}{Softmax}{definicion.2.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.3}Propagación hacia adelante}{29}{subsection.2.2.3}\protected@file@percent }
\newlabel{eq:fp1}{{2.2.3}{29}{Propagación hacia adelante}{subsection.2.2.3}{}}
\newlabel{eq:fp2}{{2.2.3}{29}{Propagación hacia adelante}{subsection.2.2.3}{}}
\newlabel{eq:cadena-fp}{{2.2.3}{29}{Propagación hacia adelante}{subsection.2.2.3}{}}
\@writefile{brf}{\backcite{abu2012learning}{{29}{2.2.3}{subsection.2.2.3}}}
\citation{curry1944method}
\citation{molala2019sd}
\citation{shalev2014understanding}
\@writefile{loa}{\contentsline {algocf}{\numberline {1}{\ignorespaces $ForwardPropagation(\textbf  {x})$)}}{30}{algocf.1}\protected@file@percent }
\newlabel{alg:fp}{{1}{30}{Propagación hacia adelante}{algocf.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.4}Descenso en gradiente}{30}{subsection.2.2.4}\protected@file@percent }
\@writefile{brf}{\backcite{curry1944method}{{30}{2.2.4}{subsection.2.2.4}}}
\citation{ruder2016overview}
\citation{ruder2016overview}
\citation{robbins1951stochastic}
\@writefile{brf}{\backcite{molala2019sd}{{31}{2.2.4}{subsection.2.2.4}}}
\@writefile{brf}{\backcite{shalev2014understanding}{{31}{2.2.4}{subsection.2.2.4}}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.12}{\ignorespaces Ejemplo del Descenso en Gradiente en una parábola.}}{31}{figure.2.12}\protected@file@percent }
\newlabel{fig:gd}{{2.12}{31}{Ejemplo del Descenso en Gradiente en una parábola}{figure.2.12}{}}
\newlabel{def:gd}{{2.5}{31}{Descenso en grandiente}{definicion.2.5}{}}
\@writefile{brf}{\backcite{ruder2016overview}{{31}{2.2.4}{definicion.2.5}}}
\@writefile{brf}{\backcite{ruder2016overview}{{31}{2.2.4}{figure.2.13}}}
\@writefile{brf}{\backcite{robbins1951stochastic}{{31}{2.2.4}{figure.2.13}}}
\citation{ruder2016overview}
\@writefile{lof}{\contentsline {figure}{\numberline {2.13}{\ignorespaces Diferentes resultados según la tasa de aprendizaje $\mu $.}}{32}{figure.2.13}\protected@file@percent }
\newlabel{fig:lr}{{2.13}{32}{Diferentes resultados según la tasa de aprendizaje $\mu $}{figure.2.13}{}}
\@writefile{brf}{\backcite{ruder2016overview}{{32}{2.2.4}{figure.2.13}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.5}Propagación hacia atrás}{32}{subsection.2.2.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.5.1}Sensibilidades}{32}{subsubsection.2.2.5.1}\protected@file@percent }
\newlabel{eq:esample}{{2.2.5.1}{32}{Sensibilidades}{subsubsection.2.2.5.1}{}}
\newlabel{eq:ederiv}{{2.2.5.1}{32}{Sensibilidades}{subsubsection.2.2.5.1}{}}
\citation{abu2012learning}
\citation{abu2012learning}
\newlabel{def:sensibilidad}{{2.6}{33}{Vector de sensibilidad}{definicion.2.6}{}}
\@writefile{brf}{\backcite{abu2012learning}{{33}{2.2.5.1}{definicion.2.6}}}
\newlabel{eq:senpar}{{2.2.5.1}{33}{Sensibilidades}{definicion.2.6}{}}
\newlabel{eq:senpar2}{{2.2.5.1}{33}{Sensibilidades}{definicion.2.6}{}}
\@writefile{brf}{\backcite{abu2012learning}{{33}{2.2.5.1}{definicion.2.6}}}
\newlabel{eq:senpar3}{{2.2.5.1}{33}{Sensibilidades}{definicion.2.6}{}}
\newlabel{eq:delta-ele}{{2.2.5.1}{33}{Sensibilidades}{definicion.2.6}{}}
\@writefile{loa}{\contentsline {algocf}{\numberline {2}{\ignorespaces $BackPropagation(\textbf  {x}, y)$}}{34}{algocf.2}\protected@file@percent }
\newlabel{alg:bp}{{2}{34}{Sensibilidades}{algocf.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.5.2}Aprendizaje}{34}{subsubsection.2.2.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.6}Error y sobreajuste}{34}{subsection.2.2.6}\protected@file@percent }
\@writefile{loa}{\contentsline {algocf}{\numberline {3}{\ignorespaces $AprendizajeRed(X, \textbf  {y}, \mu , tam_{batch})$}}{35}{algocf.3}\protected@file@percent }
\newlabel{alg:sgd-nn}{{3}{35}{Aprendizaje}{algocf.3}{}}
\citation{bhande2018overfitting}
\citation{vapnik2015uniform}
\citation{hertz2018introduction}
\citation{hinton2012improving}
\citation{krogh1992simple}
\citation{julien2018overfitting}
\@writefile{brf}{\backcite{bhande2018overfitting}{{36}{2.2.6}{subsection.2.2.6}}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.14}{\ignorespaces Efecto del \emph  {overfitting} y \emph  {underfitting}.}}{36}{figure.2.14}\protected@file@percent }
\newlabel{fig:overfitting}{{2.14}{36}{Efecto del \emph {overfitting} y \emph {underfitting}}{figure.2.14}{}}
\@writefile{brf}{\backcite{vapnik2015uniform}{{36}{2.2.6}{figure.2.14}}}
\@writefile{brf}{\backcite{hertz2018introduction, hinton2012improving}{{36}{2.2.6}{figure.2.14}}}
\newlabel{eq:l1}{{2.2.6}{36}{Error y sobreajuste}{figure.2.14}{}}
\@writefile{brf}{\backcite{krogh1992simple}{{36}{2.2.6}{figure.2.14}}}
\newlabel{eq:l2}{{2.2.6}{36}{Error y sobreajuste}{figure.2.14}{}}
\citation{cybenko1989approximation}
\citation{lu2017expressive}
\citation{leshno1993multilayer}
\citation{cybenko1989approximation}
\@writefile{brf}{\backcite{julien2018overfitting}{{37}{2.2.6}{figure.2.14}}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.15}{\ignorespaces Sobreajuste entrenando una red neuronal, tenemos que parar antes de que las curvas diverjan.}}{37}{figure.2.15}\protected@file@percent }
\newlabel{fig:overfitting-nn}{{2.15}{37}{Sobreajuste entrenando una red neuronal, tenemos que parar antes de que las curvas diverjan}{figure.2.15}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.7}Teorema de aproximación universal}{37}{subsection.2.2.7}\protected@file@percent }
\@writefile{brf}{\backcite{cybenko1989approximation}{{37}{2.2.7}{subsection.2.2.7}}}
\@writefile{brf}{\backcite{lu2017expressive}{{37}{2.2.7}{subsection.2.2.7}}}
\newlabel{th:aproxuni-anchura}{{2.1}{37}{Teorema de aproximación universal (anchura indeterminada)}{teorema.2.1}{}}
\@writefile{brf}{\backcite{leshno1993multilayer}{{37}{2.2.7}{teorema.2.1}}}
\citation{cybenko1989approximation}
\citation{rudin1973functional}
\citation{rudin2006real}
\citation{cybenko1989approximation}
\@writefile{brf}{\backcite{cybenko1989approximation}{{38}{2.2.7}{teorema.2.1}}}
\newlabel{def:discriminatoria}{{2.7}{38}{Función discriminatoria}{definicion.2.7}{}}
\@writefile{brf}{\backcite{cybenko1989approximation}{{38}{2.2.7}{definicion.2.7}}}
\newlabel{th:uni1}{{2.2}{38}{}{teorema.2.2}{}}
\@writefile{brf}{\backcite{rudin1973functional}{{38}{2.2.7}{teorema.2.2}}}
\@writefile{brf}{\backcite{rudin2006real}{{38}{2.2.7}{teorema.2.2}}}
\@writefile{brf}{\backcite{cybenko1989approximation}{{38}{2.2.7}{teorema.2.2}}}
\newlabel{lema:uni1}{{2.1}{38}{}{lema.2.1}{}}
\citation{lecun1995convolutional}
\newlabel{th:aproxuni-prof}{{2.3}{39}{Teorema de aproximación universal (profundidad indeterminada)}{teorema.2.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Clasificación}{39}{section.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Aprendizaje}{39}{subsection.2.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}Arquitectura}{39}{subsection.2.3.2}\protected@file@percent }
\citation{pelatrion2020conv}
\citation{bansal2018conv}
\citation{graham2014fractional}
\citation{yani2019application}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.3}Redes Neuronales Convolucionales}{40}{subsection.2.3.3}\protected@file@percent }
\@writefile{brf}{\backcite{lecun1995convolutional}{{40}{2.3.3}{subsection.2.3.3}}}
\newlabel{def:convolucion}{{2.8}{40}{Convolución $N$-D discreta}{definicion.2.8}{}}
\@writefile{brf}{\backcite{pelatrion2020conv}{{40}{2.3.3}{definicion.2.8}}}
\@writefile{brf}{\backcite{bansal2018conv}{{40}{2.3.3}{definicion.2.8}}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.16}{\ignorespaces Ejemplo de aplicación de convolución 2D.}}{40}{figure.2.16}\protected@file@percent }
\newlabel{fig:convolucion-2d}{{2.16}{40}{Ejemplo de aplicación de convolución 2D}{figure.2.16}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.17}{\ignorespaces Ejemplo de aplicación de convolución 3D.}}{40}{figure.2.17}\protected@file@percent }
\newlabel{fig:convolucion-3d}{{2.17}{40}{Ejemplo de aplicación de convolución 3D}{figure.2.17}{}}
\citation{saha2018cnn}
\citation{mcclelland1986parallel}
\@writefile{brf}{\backcite{graham2014fractional}{{41}{2.3.3}{figure.2.17}}}
\@writefile{brf}{\backcite{yani2019application}{{41}{2.3.3}{figure.2.17}}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.18}{\ignorespaces Ejemplo de \emph  {max-pooling} y \emph  {average-pooling}.}}{41}{figure.2.18}\protected@file@percent }
\newlabel{fig:pooling}{{2.18}{41}{Ejemplo de \emph {max-pooling} y \emph {average-pooling}}{figure.2.18}{}}
\@writefile{brf}{\backcite{saha2018cnn}{{41}{2.3.3}{figure.2.18}}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.19}{\ignorespaces Ejemplo de estructura de CNN.}}{41}{figure.2.19}\protected@file@percent }
\newlabel{fig:ejemplo-cnn}{{2.19}{41}{Ejemplo de estructura de CNN}{figure.2.19}{}}
\citation{sancho2020ae}
\citation{sancho2020ae}
\citation{kullback1951information}
\citation{sancho2020ae}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.4}Autocodificador}{42}{subsection.2.3.4}\protected@file@percent }
\newlabel{sec:autoencoder}{{2.3.4}{42}{Autocodificador}{subsection.2.3.4}{}}
\@writefile{brf}{\backcite{mcclelland1986parallel}{{42}{2.3.4}{subsection.2.3.4}}}
\@writefile{brf}{\backcite{sancho2020ae}{{42}{2.3.4}{subsection.2.3.4}}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.20}{\ignorespaces Ejemplo de estructura de un autocodificador}}{42}{figure.2.20}\protected@file@percent }
\newlabel{fig:ej-ae}{{2.20}{42}{Ejemplo de estructura de un autocodificador}{figure.2.20}{}}
\@writefile{brf}{\backcite{sancho2020ae}{{42}{2.3.4}{figure.2.20}}}
\@writefile{brf}{\backcite{kullback1951information}{{42}{2.3.4}{figure.2.21}}}
\newlabel{eq:divergencia}{{2.3.4}{42}{Autocodificador}{figure.2.21}{}}
\citation{goodfellow2014generative}
\citation{thalles2018gan}
\@writefile{lof}{\contentsline {figure}{\numberline {2.21}{\ignorespaces Ejemplo de estructura de un autocodificador variacional}}{43}{figure.2.21}\protected@file@percent }
\newlabel{fig:ej-vae}{{2.21}{43}{Ejemplo de estructura de un autocodificador variacional}{figure.2.21}{}}
\@writefile{brf}{\backcite{sancho2020ae}{{43}{2.3.4}{figure.2.21}}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.22}{\ignorespaces Ejemplo de generador de caras usando un VAE entrenado con caras reales.}}{43}{figure.2.22}\protected@file@percent }
\newlabel{fig:caras}{{2.22}{43}{Ejemplo de generador de caras usando un VAE entrenado con caras reales}{figure.2.22}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.5}Redes Generativas Antagónicas}{43}{subsection.2.3.5}\protected@file@percent }
\@writefile{brf}{\backcite{goodfellow2014generative}{{43}{2.3.5}{subsection.2.3.5}}}
\@writefile{brf}{\backcite{thalles2018gan}{{43}{2.3.5}{subsection.2.3.5}}}
\citation{nguyen2020deepfake}
\citation{elman1990finding}
\citation{christopher2015lstm}
\citation{christopher2015lstm}
\citation{christopher2015lstm}
\@writefile{lof}{\contentsline {figure}{\numberline {2.23}{\ignorespaces Estructura de una red GAN con dígitos.}}{44}{figure.2.23}\protected@file@percent }
\newlabel{fig:gan}{{2.23}{44}{Estructura de una red GAN con dígitos}{figure.2.23}{}}
\@writefile{brf}{\backcite{nguyen2020deepfake}{{44}{2.3.5}{figure.2.23}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.6}Redes Neuronales Recurrentes}{44}{subsection.2.3.6}\protected@file@percent }
\@writefile{brf}{\backcite{elman1990finding}{{44}{2.3.6}{subsection.2.3.6}}}
\@writefile{brf}{\backcite{christopher2015lstm}{{44}{2.3.6}{subsection.2.3.6}}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.24}{\ignorespaces Estructura de una RNN.}}{44}{figure.2.24}\protected@file@percent }
\newlabel{fig:rnn-rolled}{{2.24}{44}{Estructura de una RNN}{figure.2.24}{}}
\@writefile{brf}{\backcite{christopher2015lstm}{{44}{2.3.6}{figure.2.24}}}
\citation{christopher2015lstm}
\citation{bengio1994learning}
\citation{Goodfellow-et-al-2016}
\citation{hochreiter1997long}
\@writefile{lof}{\contentsline {figure}{\numberline {2.25}{\ignorespaces Estructura de una RNN desenrollada.}}{45}{figure.2.25}\protected@file@percent }
\newlabel{fig:rnn-unrolled}{{2.25}{45}{Estructura de una RNN desenrollada}{figure.2.25}{}}
\@writefile{brf}{\backcite{christopher2015lstm}{{45}{2.3.6}{figure.2.25}}}
\newlabel{eq:rnn}{{2.3.6}{45}{Redes Neuronales Recurrentes}{figure.2.25}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.26}{\ignorespaces Estructura de una neurona en una RNN.}}{45}{figure.2.26}\protected@file@percent }
\newlabel{fig:rnn-cells}{{2.26}{45}{Estructura de una neurona en una RNN}{figure.2.26}{}}
\@writefile{brf}{\backcite{christopher2015lstm}{{45}{2.3.6}{figure.2.26}}}
\@writefile{brf}{\backcite{bengio1994learning}{{45}{2.3.6}{figure.2.26}}}
\@writefile{brf}{\backcite{Goodfellow-et-al-2016}{{45}{2.3.6}{figure.2.27}}}
\@writefile{brf}{\backcite{hochreiter1997long}{{45}{2.3.6}{figure.2.27}}}
\citation{christopher2015lstm}
\citation{christopher2015lstm}
\citation{christopher2015lstm}
\@writefile{lof}{\contentsline {figure}{\numberline {2.27}{\ignorespaces La información de $x_1$ y $x_2$ no llega para $h_{t+1}$.}}{46}{figure.2.27}\protected@file@percent }
\newlabel{fig:rnn-longterm}{{2.27}{46}{La información de $x_1$ y $x_2$ no llega para $h_{t+1}$}{figure.2.27}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}LSTM}{46}{section.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.1}Estructura general}{46}{subsection.2.4.1}\protected@file@percent }
\@writefile{brf}{\backcite{christopher2015lstm}{{46}{2.4.1}{subsection.2.4.1}}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.28}{\ignorespaces Ejemplo de puerta.}}{46}{figure.2.28}\protected@file@percent }
\newlabel{fig:gate}{{2.28}{46}{Ejemplo de puerta}{figure.2.28}{}}
\@writefile{brf}{\backcite{christopher2015lstm}{{46}{2.4.1}{figure.2.28}}}
\citation{christopher2015lstm}
\citation{christopher2015lstm}
\@writefile{lof}{\contentsline {figure}{\numberline {2.29}{\ignorespaces Esquema de célula LSTM.}}{47}{figure.2.29}\protected@file@percent }
\newlabel{fig:lstm-cells}{{2.29}{47}{Esquema de célula LSTM}{figure.2.29}{}}
\@writefile{brf}{\backcite{christopher2015lstm}{{47}{2.4.1}{figure.2.29}}}
\newlabel{eq:forget}{{2.4.1}{47}{Estructura general}{figure.2.29}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.30}{\ignorespaces Puerta del olvido $f_t$.}}{47}{figure.2.30}\protected@file@percent }
\newlabel{fig:forget}{{2.30}{47}{Puerta del olvido $f_t$}{figure.2.30}{}}
\@writefile{brf}{\backcite{christopher2015lstm}{{47}{2.4.1}{figure.2.30}}}
\newlabel{eq:input1}{{2.4.1}{47}{Estructura general}{figure.2.30}{}}
\newlabel{eq:input2}{{2.4.1}{47}{Estructura general}{figure.2.30}{}}
\citation{christopher2015lstm}
\citation{gers2000recurrent}
\@writefile{lof}{\contentsline {figure}{\numberline {2.31}{\ignorespaces Puerta de entrada $i_t$ e información de la neurona $\setbox \z@ \hbox {\mathsurround \z@ $\textstyle C$}\mathaccent "0365{C}_t$.}}{48}{figure.2.31}\protected@file@percent }
\newlabel{fig:input}{{2.31}{48}{Puerta de entrada $i_t$ e información de la neurona $\widetilde {C}_t$}{figure.2.31}{}}
\@writefile{brf}{\backcite{christopher2015lstm}{{48}{2.4.1}{figure.2.31}}}
\newlabel{eq:celular}{{2.4.1}{48}{Estructura general}{figure.2.31}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.32}{\ignorespaces Estado celular $C_t$.}}{48}{figure.2.32}\protected@file@percent }
\newlabel{fig:celular}{{2.32}{48}{Estado celular $C_t$}{figure.2.32}{}}
\@writefile{brf}{\backcite{christopher2015lstm}{{48}{2.4.1}{figure.2.32}}}
\newlabel{eq:output1}{{2.4.1}{48}{Estructura general}{figure.2.32}{}}
\newlabel{eq:output2}{{2.4.1}{48}{Estructura general}{figure.2.32}{}}
\citation{christopher2015lstm}
\citation{gers2000recurrent}
\citation{christopher2015lstm}
\citation{cho2014learning}
\@writefile{lof}{\contentsline {figure}{\numberline {2.33}{\ignorespaces Puerta de salida $o_t$.}}{49}{figure.2.33}\protected@file@percent }
\newlabel{fig:output}{{2.33}{49}{Puerta de salida $o_t$}{figure.2.33}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.2}Variantes}{49}{subsection.2.4.2}\protected@file@percent }
\@writefile{brf}{\backcite{gers2000recurrent}{{49}{2.4.2}{subsection.2.4.2}}}
\newlabel{eq:variante1}{{2.4.2}{49}{Variantes}{subsection.2.4.2}{}}
\@writefile{brf}{\backcite{christopher2015lstm}{{49}{2.4.2}{subsection.2.4.2}}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.34}{\ignorespaces Variante que introduce cauces de $C_{t-1}$ con las puertas.}}{49}{figure.2.34}\protected@file@percent }
\newlabel{fig:variante1}{{2.34}{49}{Variante que introduce cauces de $C_{t-1}$ con las puertas}{figure.2.34}{}}
\@writefile{brf}{\backcite{gers2000recurrent}{{49}{2.4.2}{figure.2.34}}}
\@writefile{brf}{\backcite{christopher2015lstm}{{49}{2.4.2}{figure.2.34}}}
\newlabel{eq:variante2}{{2.4.2}{49}{Variantes}{figure.2.34}{}}
\citation{christopher2015lstm}
\citation{greff2016lstm}
\citation{gers1999learning}
\citation{Goodfellow-et-al-2016}
\@writefile{lof}{\contentsline {figure}{\numberline {2.35}{\ignorespaces Variante que sustituye la puerta de entrada por la negación de la del olvido.}}{50}{figure.2.35}\protected@file@percent }
\newlabel{fig:variante2}{{2.35}{50}{Variante que sustituye la puerta de entrada por la negación de la del olvido}{figure.2.35}{}}
\@writefile{brf}{\backcite{cho2014learning}{{50}{2.4.2}{figure.2.35}}}
\newlabel{eq:gru}{{2.4.2}{50}{Variantes}{figure.2.35}{}}
\@writefile{brf}{\backcite{christopher2015lstm}{{50}{2.4.2}{figure.2.35}}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.36}{\ignorespaces Estructura de la variante GRU.}}{50}{figure.2.36}\protected@file@percent }
\newlabel{fig:gru}{{2.36}{50}{Estructura de la variante GRU}{figure.2.36}{}}
\@writefile{brf}{\backcite{greff2016lstm}{{50}{2.4.2}{figure.2.36}}}
\@writefile{brf}{\backcite{gers1999learning}{{50}{2.4.2}{figure.2.36}}}
\citation{pascanu2013difficulty}
\citation{Goodfellow-et-al-2016}
\@writefile{brf}{\backcite{Goodfellow-et-al-2016}{{51}{2.4.2}{figure.2.36}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.3}Recorte}{51}{subsection.2.4.3}\protected@file@percent }
\@writefile{brf}{\backcite{pascanu2013difficulty}{{51}{2.4.3}{subsection.2.4.3}}}
\newlabel{eq:clipping}{{2.4.3}{51}{Recorte}{subsection.2.4.3}{}}
\@writefile{brf}{\backcite{Goodfellow-et-al-2016}{{51}{2.4.3}{subsection.2.4.3}}}
\@setckpt{conceptos-previos/aprendizaje-profundo}{
\setcounter{page}{52}
\setcounter{equation}{0}
\setcounter{enumi}{2}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{part}{1}
\setcounter{chapter}{2}
\setcounter{section}{4}
\setcounter{subsection}{3}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{36}
\setcounter{table}{0}
\setcounter{parentequation}{0}
\setcounter{lstnumber}{1}
\setcounter{teorema}{3}
\setcounter{proposicion}{0}
\setcounter{lema}{1}
\setcounter{corolario}{0}
\setcounter{definicion}{8}
\setcounter{ejemplo}{0}
\setcounter{observacion}{0}
\setcounter{AlgoLine}{20}
\setcounter{algocfline}{3}
\setcounter{algocfproc}{3}
\setcounter{algocf}{3}
\setcounter{lofdepth}{1}
\setcounter{lotdepth}{1}
\setcounter{Item}{7}
\setcounter{Hfootnote}{0}
\setcounter{bookmark@seq@number}{0}
\setcounter{lstlisting}{0}
\setcounter{section@level}{2}
}
