% !TeX root = ../../tfg.tex
% !TeX encoding = utf8
%
%*******************************************************
% Introducción artículo MFNAUA
%*******************************************************

\chapter{Las redes neuronales multicapa son aproximadores universales}  

\section{Introducción}  

Tras las definiciones y construcciones expuestas durante el capítulo de presentación 
y construcción de las redes neuronales 
es pertinente la pregunta de si toda las estructuras y técnicas presentadas solventan nuestro 
objetivo principal: Aproximar
con éxito una función genérica desconocida.   

Aunque las redes neuronales multicapa ya se venían aplicando con anterioridad \cite{4307059}, 
no fue hasta 1988 que se descubrió formalmente su alcance.
 Tal delimitación se propuso en el artículo \cite{HORNIK1989359}
\textbf{Multilayer Feedforward Networks are Universal Approximators}
 escrito por Kurt Hornik, Maxwell Stinchcombe y Halber White enunciando 

\begin{teorema}\textbf{Las redes feedforward multicapa son una clase de aproximadores universales } \label{teo:MFNAUA}
    \\
    Una red neuronal feedfoward multicapa estándar con tan solo una capa oculta y con una función de activación cualquiera es capaz de aproximar cualquier 
    función Borel medible  con dominios y codominios de dimensión finita (no necesariamente iguales) y con el nivel de precisión que se desee siempre y cuando 
    se utilicen suficientes neuronas. En este sentido las redes feedfoward multicapa son una clase de aproximadores universales.

\end{teorema}

En las secciones siguientes, con el fin de alcanzar una comprensión profunda de las redes neuronales,
trataremos de desgranar y profundizar en el artículo y su demostración. 

