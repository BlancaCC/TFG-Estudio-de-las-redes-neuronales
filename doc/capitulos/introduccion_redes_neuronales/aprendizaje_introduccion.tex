% !TeX root = ../../tfg.tex
% !TeX encoding = utf8
%
%*******************************************************
% Qué es el aprendizaje automático
%*******************************************************

\section{Concepto de aprendizaje}\label{sec:Aprendizaje}

El término de Aprendizaje Automático 
\cite{hisour} 
fue acuñado en 1959 por Arthur Samuel 
para hacer referencia a los sistemas informáticos que 
pudiesen \textit{aprender} por sí mismos, es decir, mejorar su 
eficacia y rendimiento de forma autónoma a partir de los datos, 
sin que en esas mejoras intervenga un programador.

Fue en 1997 cuando Tom Mitchell propuso una definición 
formal de aprendizaje 
\cite{tom-michell-machine-learning}, 
aproximada a la dada en el libro \textit{Learning from data}
\cite{learning-from-data-1-2}, que expondremos en seguida.

El aprendizaje es un proceso por el cual se estima una dependencia desconocida 
(input-output) o la estructura de un sistema a partir de un número finito de 
observaciones. Se compone de tres elementos principales: 

\begin{itemize}
    \item Un generador o función de distribución de la cual se extraen 
    vectores aleatorios 
    $x \in I \subset \mathbb R^ n$ 
    que dependen de una función de densidad desconocida \footnote{De hecho, encontrar esta función resolvería el problema de aprendizaje}.
    
    \item Un sistema que produce un vector de salida $y$ por cada entrada del vector $x$ a partir del valor fijo $p(y|x)$, que es desconocido también. 
    
    \item Una \textit{learning machine} dependiente de parámetros $w$, que en el caso más general no es  más que un conjunto de funciones abstractas cuyos elementos son de la forma $f(x,w)$.
\end{itemize}



Así pues, el objetivo del aprendizaje automático es encontrar una función que se aproxime a la función de densidad desconocida.

Por lo general la teoría se fundamenta en minimizar el error de estimadores, como el error cuadrático medio, ya que este se trata de un UMVUE  (estimador insesgado de mínima varianza). 

$$ECM = \frac{1}{n} \sum_{i=0} ^n (f(x_i) - y_i)^2,$$

donde $f(x_i)$ representa la predicción y $y_i$ la etiqueta de entrenamiento de $x_i$, es decir, su valor real.

% Componentes del aprendizaje   
\subsection{Componentes del aprendizaje}\label{sub:componentes_aprendizaje}  
A nivel práctico y en nuestro caso, los elementos que consideraremos para el aprendizaje y los cuales 
serán susceptibles de contribuir a la optimización buscada son
(capítulo 1 \cite{MostafaLearningFromData}): 


\begin{itemize}
    \item Espacio muestral $\mathcal X$.  
    \item Una función objetivo ideal y desconocida
     $f: \mathcal X \longrightarrow \mathcal{Y},$ 
     donde  $\mathcal{Y}$ es el conjunto de posibles valores asociados. 
    \item Un conjunto de datos de entrenamiento $\mathcal D$, donde los elementos son pares $(x,y)$ con $x \in  \mathcal X$ y 
    $y \in \mathcal{Y}$ y que representa una observación $f(x)=y.$
    \item Un algoritmo de aprendizaje que consiste en seleccionar una fórmula $g: \mathcal X \longrightarrow \mathcal{Y}$ que aproxime $f$. La fórmula $g$ pertenece 
    a un conjunto $\mathcal H$ de hipótesis. 
\end{itemize}

En nuestro caso $\mathcal{H}$ será el conjunto de todas las posibles redes neuronales y $g$ la red neuronal seleccionada. 


% Tipos de aprendizaje 
\subsection{Tipos de aprendizaje}  

El aprendizaje a partir de los datos trata en esencia de modelizar un patrón o ley del proceso subyacente a partir de un conjunto finito de muestras.  
En función de ciertas características del conjunto de datos se 
tienen distintos tipos de aprendizaje y cabe la pregunta de en qué ámbitos son útiles las redes neuronales o si resultados en problemas 
 concretos 
son extensibles a otros. 

Con el fin de tener una clara distinción,
establecemos por consiguiente la siguiente clasificación sobre los tipos de aprendizajes existentes basa en el
artículo \cite{importancia-arte-aprendizaje-automatico},
 el capítulo 1 \cite{MostafaLearningFromData}
 y capítulo 4 pag 179
\cite{BishopPaterRecognition}).

\subsubsection{Aprendizaje supervisado}
Cuando el conjunto de datos de entrenamiento contiene de manera explícita lo que es una salida correcta respecto a una entrada estamos frente a un caso de \textbf{aprendizaje no supervisado}.   
Este tipo de aprendizaje resuelve tareas de clasificación, donde la salida es discreta 
o de regresión, con una salida continua.
Un ejemplo sería el reconocimiento de dígitos  manuscritos donde cada imagen de un dígito tiene asociado cuál es. 



\subsubsection{Aprendizaje por refuerzo}  
Se trata de un problema de aprendizaje por refuerzo 
cuando conjunto de datos de entrenamiento no explicita la salida, en su lugar contiene posibles salidas junto a la bondad de éstas. 

Pongamos por ejemplo que se quiere enseñar a un sistema a jugar
a las damas; de todo el espacio de jugadas posibles, se conocerían tan solo el resultado de algunas situaciones, por ejemplo en la que uno de los jugadores ha ganado.  


\subsubsection{Aprendizaje no supervisado}  

En este tipo de aprendizaje, los datos de entrenamiento tampoco contienen ninguna información de la salida.
 Tan solo se tienen los datos de entrada. El \textbf{aprendizaje no supervisado} 
 consiste en la tarea de encontrar patrones y estructuras en los datos de entrada, 
 así como de crear una una abstracción de los datos.  Son problemas de \textit{clustering}, asociación, detección de anomalías ...

\subsubsection{Aprendizaje semi supervisado }
Combina tanto datos etiquetados como no etiquetados, 
se utiliza en problemas de clasificación o \textit{clustering}
como por ejemplo en traducción o detección de fraudes.


Las redes neuronales son partícipes en los tres tipos de aprendizaje 
recién mencionados
\cite{8612259}, \cite{DBLP:journals/corr/BakerGNR16}, \cite{10.5555/2955491.2955578}. Sin embargo centraremos nuestro estudio en el caso 
de aprendizaje supervisado. 


\subsection{El gradiente descendente} \label{sec:gradiente-descendente}

(Información tomada de los capítulos uno y dos de \cite{learning-from-data-1-2})
Así pues, una vez concretado el problema y sus elementos 
(\ref{sub:componentes_aprendizaje}) es necesario definir un método con el que aproximar la función ideal $f,$ para ello introduciremos el algoritmo de gradiente descendente.  

El gradiente descendente es un método iterativo de minimización de funciones diferenciables. 

En nuestro caso particular se quiere aproximar la función ideal desconocida $f$ a partir de funciones (redes neuronales) $h_w \in \mathcal{H}$, donde $w \in M(\R)_{m \times n}$ son parámetros que caracterizan a $h_w$.
Para  
Dada también una función de error diferenciable y que no presente puntos de inflexión
$E: M(\R)_{m \times n} \longrightarrow \R,$
se toma una matriz inicial  cualquiera $w_0 \in M(\R)_{m \times n}$ y 
fijado $\eta \in \R^+$. 

Se define la sucesión 
\begin{equation}
    w_{t+1}  = w_t - \eta \nabla E(w_t).
\end{equation}  

Donde $w_n$ es una sucesión cuyos términos convergen a un mínimo local.
\subsubsection*{Observaciones sobre el algoritmo }

\begin{itemize}
    \item El algoritmo solo encuentra óptimos locales con una dependencia crucial del valor de inicio. 
    \item La convergencia no es segura en un tiempo finito y requiere de criterios de parada. 
    \item Si la función es convexa el mínimo será global.
    \item El parámetro $\eta$ puede ser cualquiera y debe de ser fijado o controlado por el diseñador.  
\end{itemize}


\subsection{Comentario de Blanca que deja aquí por guardarlo en algún sitio y que en algún momento debiera de borrar} 

\textcolor{blue}{
Estamos buscando verdaderamente no una función ideal sino 
la clase de equivalencia de las funciones medibles que coincide su grafo en un conjunto numerable de puntos. 
En la práctica nos quedamos con un candidato de esa clase. ¿ Afectar esta forma de ver las cosas?
}
