%----- Teoría de la aproximación -----
% Texto principal del que se ha sacado 
@book{the-elements-of-real-analysis,
  title={The elements of real analysis},
  author={Robert G. Bartle},
  year={1947},
  publisher={John. Wiley \& Sons}
}

% ---------- Introducción a las redes neuronales -------

@book{learning-from-data-1-2,
  title={Learning From Data: Concepts, Theory, and Methods},
  author={Vladimir Cherkassky and Filip Mulier},
  year={2007},
  publisher={John. Wiley \& Sons},
  edition        = {2}, 
  chapter        = {1,2},
}

@online{e-chapter-7-neural-networks,
  author = { Yaser Abu-Mostafa, Malik Magdon-Ismail, Hsuan-Tien Li},
  title = {{Neural Networks}},
  year = {2015},
  urldate = {Jan-2015},
  chapter = {7},
}

% historia redes neuronales  
@online{hisour,
  author = {Hisour},
  title = {Nocción del aprendizaje automático},
  year = 2021,
  url = {https://www.hisour.com/es/machine-learning-42773/},
  urldate = {2021-11-27}
}

@online{samuel-wikipedia,
  author= {Wikipedia. Arthur Samuel},
  url = {https://en.wikipedia.org/wiki/Arthur_Samuel},
  urldate = {2021-11-30}
}
@book{tom-michell-machine-learning,
   title={Machine Learing},
   author={Tom Mitchell},
   year={1997},
   publisher={McGraw},
    url = {https://www.cs.cmu.edu/afs/cs.cmu.edu/user/mitchell/ftp/mlbook.html},
}
@online{mitchell-wikipedia,
  author= {Wikipedia. Tom Mitchell},
  url = {https://en.wikipedia.org/wiki/Tom_M._Mitchell},
  urldate = {2021-11-30}
}


%% ------ Redes neuronales como aproximadores universales  -----
% Conferencia de 1987 sobre redes neuronales
@ARTICLE{4307059,
  author={},
  journal={IEEE Expert}, 
  title={IEEE First Annual International Conference on Neural Networks San Diego, California June 21-24, 1987}, 
  year={1987},
  volume={2},
  number={2},
  pages={14-14},
  doi={10.1109/MEX.1987.4307059}}

% Artículo principal: Multilayer feedforward networks are universal approximators
@article{HORNIK1989359,
title = {Multilayer feedforward networks are universal approximators},
journal = {Neural Networks},
volume = {2},
number = {5},
pages = {359-366},
year = {1989},
issn = {0893-6080},
doi = {https://doi.org/10.1016/0893-6080(89)90020-8},
url = {https://www.sciencedirect.com/science/article/pii/0893608089900208},
author = {Kurt Hornik and Maxwell Stinchcombe and Halbert White},
keywords = {Feedforward networks, Universal approximation, Mapping networks, Network representation capability, Stone-Weierstrass Theorem, Squashing functions, Sigma-Pi networks, Back-propagation networks},
abstract = {This paper rigorously establishes that standard multilayer feedforward networks with as few as one hidden layer using arbitrary squashing functions are capable of approximating any Borel measurable function from one finite dimensional space to another to any desired degree of accuracy, provided sufficiently many hidden units are available. In this sense, multilayer feedforward networks are a class of universal approximators.}
}
% Imagen perceptrón multicapa  
@misc{alma991008058419704990,
publisher = {AMLbook.com},
title = {Learning from data : a short course },
year = {2012},
author = {Abu-Mostafa, Yaser S.},
address = {Seattle},
booktitle = {Learning from data : a short course},
isbn = {9781600490064},
keywords = {Aprendizaje automático},
language = {eng},
}
% Libro para algunas demostraciones de teoría de la medida
% Se cita en pag 228 teorema 52.G
% Se cita en pag 241-242  teorema 55.C y 55.D
@Book{ nla.cat-vn1819421,
author = { Halmos, Paul R. },
title = { Measure theory / [by] Paul R. Halmos },
isbn = { 0387900888 },
publisher = { Springer-Verlag New York },
year = { 1974 },
type = { Book },
url = { http://www.loc.gov/catdir/enhancements/fy0814/74010690-t.html },
language = { English },
subjects = { Measure theory. },
life-dates = { 1974 -  },
catalogue-url = { https://nla.gov.au/nla.cat-vn1819421 },
}




