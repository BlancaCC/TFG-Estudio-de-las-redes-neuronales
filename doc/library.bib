%----- Teoría de la aproximación -----
% Texto principal del que se ha sacado 
@book{the-elements-of-real-analysis,
  title={The elements of real analysis},
  author={Robert G. Bartle},
  year={1947},
  publisher={John. Wiley \& Sons}
}

% ---------- Introducción a las redes neuronales -------

@book{learning-from-data-1-2,
  title={Learning From Data: Concepts, Theory, and Methods},
  author={Vladimir Cherkassky and Filip Mulier},
  year={2007},
  publisher={John. Wiley \& Sons},
  edition        = {2}, 
  chapter        = {1,2},
}

@online{e-chapter-7-neural-networks,
  author = { Yaser Abu-Mostafa, Malik Magdon-Ismail, Hsuan-Tien Li},
  title = {{Neural Networks}},
  year = {2015},
  urldate = {Jan-2015},
  chapter = {7},
}

% algoritmo backpropagation 
@article{backpropagation-Hinton,
	abstract = {We describe a new learning procedure, back-propagation, for networks of neurone-like units. The procedure repeatedly adjusts the weights of the connections in the network so as to minimize a measure of the difference between the actual output vector of the net and the desired output vector. As a result of the weight adjustments, internal `hidden'units which are not part of the input or output come to represent important features of the task domain, and the regularities in the task are captured by the interactions of these units. The ability to create useful new features distinguishes back-propagation from earlier, simpler methods such as the perceptron-convergence procedure1.},
	author = {Rumelhart, David E. and Hinton, Geoffrey E. and Williams, Ronald J.},
	da = {1986/10/01},
	date-added = {2022-02-22 07:39:52 +0100},
	date-modified = {2022-02-22 07:40:25 +0100},
	doi = {10.1038/323533a0},
	id = {Rumelhart1986},
	isbn = {1476-4687},
	journal = {Nature},
	number = {6088},
	pages = {533--536},
	read = {0},
	title = {Learning representations by back-propagating errors},
	ty = {JOUR},
	url = {https://doi.org/10.1038/323533a0},
	volume = {323},
	year = {1986},
	Bdsk-Url-1 = {https://doi.org/10.1038/323533a0}
  }


% historia redes neuronales  
@online{hisour,
  author = {Hisour},
  title = {Nocción del aprendizaje automático},
  year = 2021,
  url = {https://www.hisour.com/es/machine-learning-42773/},
  urldate = {2021-11-27}
}

@online{samuel-wikipedia,
  author= {Wikipedia. Arthur Samuel},
  url = {https://en.wikipedia.org/wiki/Arthur_Samuel},
  urldate = {2021-11-30}
}
@book{tom-michell-machine-learning,
   title={Machine Learing},
   author={Tom Mitchell},
   year={1997},
   publisher={McGraw},
    url = {https://www.cs.cmu.edu/afs/cs.cmu.edu/user/mitchell/ftp/mlbook.html},
}
@online{mitchell-wikipedia,
  author= {Wikipedia. Tom Mitchell},
  url = {https://en.wikipedia.org/wiki/Tom_M._Mitchell},
  urldate = {2021-11-30}
}


%%% ----- Construcción de las redes neuronales   --------
%% Manual muy extenso , lo has usado para
%% Definición perceptrón 
%% Feedforward networks functions: capítulo 5 páginas 227-256
@book{BishopPaterRecognition,
author = {Bishop, Christopher M.}, 
title = {Pattern Recognition and Machine Learning (Information Science and Statistics)}, 
year = {2006}, 
isbn = {0387310738}, 
publisher = {Springer-Verlag}, 
address = {Berlin, Heidelberg} 
}

%% Manual también muy interesante
%% Usado para los tipos de aprendizaje Capítulo 1
@book{MostafaLearningFromData,  
author = {Abu-Mostafa, Yaser S. and Magdon-Ismail, Malik and Lin, Hsuan-Tien}, 
title = {Learning From Data}, 
year = {2012}, 
isbn = {1600490069},
 publisher = {AMLBook}, 
 abstract = {Machine learning allows computational systems to adaptively 
 improve their performance with experience accumulated from the observed
data. Its techniques are widely applied in engineering, science, finance, and commerce.
This book is designed for a short course on machine learning. It is a short course, not 
a hurried course. From over a decade of teaching this material, we have distilled what
we believe to be the core topics that every student of the subject should know. 
We chose the title `learning from data' that faithfully describes what the subject 
is about, and made it a point to cover the topics in a story-like fashion. 
Our hope is that the reader can learn all the fundamentals of the subject by 
reading the book cover to cover. ---- Learning from data has distinct theoretical
and practical tracks. In this book, we balance the theoretical and the practical,
the mathematical and the heuristic. Our criterion for inclusion is relevance. 
Theory that establishes the conceptual framework for learning is included, 
and so are heuristics that impact the performance of real learning systems. 
---- Learning from data is a very dynamic field. Some of the hot techniques
and theories at times become just fads, and others gain traction and become
part of the field. What we have emphasized in this book are the necessary 
fundamentals that give any student of learning from data a solid foundation,
and enable him or her to venture out and explore further techniques and theories, 
or perhaps to contribute their own. ---- The authors are professors at California 
Institute of Technology (Caltech), Rensselaer Polytechnic Institute (RPI), 
and National Taiwan University (NTU), where this book is the main text for 
their popular courses on machine learning. The authors also consult extensively 
with financial and commercial companies on machine learning applications,
and have led winning teams in machine learning competitions.}          
}


%% Ejemplos de tipo de aprendizaje en los que se utiliza redes neuronales: 

% artículo donde en el estado del arte dice que se aplica en 
% todas los tipos de aprendizajes 
%y indica como mejorarlo en el no supervisado 

@INPROCEEDINGS{8612259,
  author={Dike, Happiness Ugochi and Zhou, Yimin and Deveerasetty, Kranthi Kumar and Wu, Qingtian},
  booktitle={2018 IEEE International Conference on Cyborg and Bionic Systems (CBS)}, 
  title={Unsupervised Learning Based On Artificial Neural Network: A Review}, 
  year={2018},
  volume={},
  number={},
  pages={322-327},
  doi={10.1109/CBS.2018.8612259}}

% para aprendizaje por refuerzo 
@article{DBLP:journals/corr/BakerGNR16,
  author    = {Bowen Baker and
               Otkrist Gupta and
               Nikhil Naik and
               Ramesh Raskar},
  title     = {Designing Neural Network Architectures using Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/1611.02167},
  year      = {2016},
  url       = {http://arxiv.org/abs/1611.02167},
  eprinttype = {arXiv},
  eprint    = {1611.02167},
  timestamp = {Mon, 13 Aug 2018 16:47:42 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/BakerGNR16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
% Ejemplo que utiliza algoritmos evolutivos para configurar la
red neuronal 
@inproceedings{10.5555/2955491.2955578, 
author = {Stanley, Kenneth O. and Miikkulainen, Risto}, 
title = {Efficient Reinforcement Learning through Evolving Neural Network Topologies}, 
year = {2002}, 
isbn = {1558608788}, 
publisher = {Morgan Kaufmann Publishers Inc.}, 
address = {San Francisco, CA, USA}, 
abstract = {Neuroevolution is currently the strongest method on the pole-balancing benchmark reinforcement learning tasks. 
Although earlier studies suggested that there was an advantage in evolving the network topology as well as connection weights, the leading neuroevolution systems evolve fixed networks. 
Whether evolving structure can improve performance is an open question. In this article, we introduce such a system, NeuroEvolution of Augmenting Topologies (NEAT). We show that 
when structure is evolved (1) with a principled method of crossover, (2) by protecting structural innovation, and (3) 
through incremental growth from minimal structure, learning is
 significantly faster and stronger than with the best 
 fixed-topology methods. NEAT also shows that it is possible to evolve populations of increasingly large genomes, achieving 
 highly complex solutions that would otherwise be difficult to optimize.}, 
 booktitle = {Proceedings of the 4th Annual 
 Conference on Genetic and Evolutionary Computation}, 
 pages = {569–577}, 
 numpages = {9}, 
 location = {New York City, New York}, 
 series = {GECCO'02} 
}

%% Sobre el perceptrón 

@InProceedings{perceptron-convergence,
author="Van Der Malsburg, C.",
editor="Palm, G{\"u}nther
and Aertsen, Ad",
title="Frank Rosenblatt: Principles of Neurodynamics: Perceptrons and the Theory of Brain Mechanisms",
booktitle="Brain Theory",
year="1986",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="109-115",
abstract="Frank Rosenblatt's intention with his book, according to his own introduction, is not just to describe a machine, the perceptron, but rather to put forward a theory. He formulates a series of machines. Each machine serves to introduce a new concept.",
isbn="978-3-642-70911-1"
}






%%%%%%%%%%%%%%%%%% metodología %%%%%%%%%%%%%%
%% Descripción del desarrollo ágil en la ciencia
@article{DBLP:journals/corr/abs-2104-12545,
  author    = {Juan Juli{\'{a}}n Merelo Guerv{\'{o}}s},
  title     = {Agile (data) science: a (draft) manifesto},
  journal   = {CoRR},
  volume    = {abs/2104.12545},
  year      = {2021},
  url       = {https://arxiv.org/abs/2104.12545},
  eprinttype = {arXiv},
  eprint    = {2104.12545},
  timestamp = {Mon, 03 May 2021 17:38:30 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2104-12545.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

% sobre cómo hacer un TFG
@online{que-es-un-trabajo-fin-de-x,
  author= {Juan Juli{\'{a}}n Merelo Guerv{\'{o}}s},
  title ={Cómo llevar a término un TFG/TFM en informática},
  url = {https://jj.github.io/que-es-un-trabajo-fin-de-x/tf.html},
  urldate = {2022-02-05}
}

% sobre metodología de personas 
% https://www.interaction-design.org/literature/article/personas-why-and-how-you-should-use-them
@online{personas-why-and-how-you-should-use-them,
  author= {Rikke Friis Dam and Teo Yu Siang |},
  title ={Personas – A Simple Introduction},
  url = {https://www.interaction-design.org/literature/article/personas-why-and-how-you-should-use-them},
  urldate = {2022-02-05}
}

% mi repositorio de github :D
% https://github.com/BlancaCC/TFG-Estudio-de-las-redes-neuronales
@online{TFG-Estudio-de-las-redes-neuronales,
  author= {Blanca Cano Camarero, Juan Juli{\'{a}}n Merelo Guerv{\'{o}}s, Francisco Javier Mer{\'{i}} de la Maza },
  title ={Github, repositorio: Estudio de las redes neuronales},
  url = {https://github.com/BlancaCC/TFG-Estudio-de-las-redes-neuronales},
  urldate = {2022-02-05}
}
% HISTORIAS DE USUARIO 
% HU 01
@online{TFG-Estudio-de-las-redes-neuronales-HU01,
  author= {Blanca Cano Camarero, Juan Juli{\'{a}}n Merelo Guerv{\'{o}}s},
  title ={Github, repositorio: Estudio de las redes neuronales, Historia de usuario 1},
  url = {https://github.com/BlancaCC/TFG-Estudio-de-las-redes-neuronales/issues/48},
  urldate = {2022-02-13}
}
% HU 06
@online{TFG-Estudio-de-las-redes-neuronales-HU02,
  author= {Blanca Cano Camarero, Juan Juli{\'{a}}n Merelo Guerv{\'{o}}s},
  title ={Github, repositorio: Estudio de las redes neuronales, Historia de usuario 2},
  url = {https://github.com/BlancaCC/TFG-Estudio-de-las-redes-neuronales/issues/65},
  urldate = {2022-02-13}
}
% HU 03
@online{TFG-Estudio-de-las-redes-neuronales-HU03,
  author= {Blanca Cano Camarero, Juan Juli{\'{a}}n Merelo Guerv{\'{o}}s},
  title ={Github, repositorio: Estudio de las redes neuronales, Historia de usuario 3},
  url = {https://github.com/BlancaCC/TFG-Estudio-de-las-redes-neuronales/issues/50},
  urldate = {2022-02-13}
}
% HU 04
@online{TFG-Estudio-de-las-redes-neuronales-HU04,
  author= {Blanca Cano Camarero, Juan Juli{\'{a}}n Merelo Guerv{\'{o}}s},
  title ={Github, repositorio: Estudio de las redes neuronales, Historia de usuario 4},
  url = {https://github.com/BlancaCC/TFG-Estudio-de-las-redes-neuronales/issues/51},
  urldate = {2022-02-13}
}
% HU 05
@online{TFG-Estudio-de-las-redes-neuronales-HU05,
  author= {Blanca Cano Camarero, Juan Juli{\'{a}}n Merelo Guerv{\'{o}}s},
  title ={Github, repositorio: Estudio de las redes neuronales, Historia de usuario 5},
  url = {https://github.com/BlancaCC/TFG-Estudio-de-las-redes-neuronales/issues/64},
  urldate = {2022-02-13}
}
% HU 06
@online{TFG-Estudio-de-las-redes-neuronales-HU06,
  author= {Blanca Cano Camarero, Juan Juli{\'{a}}n Merelo Guerv{\'{o}}s},
  title ={Github, repositorio: Estudio de las redes neuronales, Historia de usuario 6},
  url = {https://github.com/BlancaCC/TFG-Estudio-de-las-redes-neuronales/issues/49},
  urldate = {2022-02-13}
}

%% Milestone
@online{TFG-Estudio-de-las-redes-neuronales-milestones,
  author= {Blanca Cano Camarero, Juan Juli{\'{a}}n Merelo Guerv{\'{o}}s, Francisco Javier Mer{\'{i}} de la Maza},
  title ={Github, repositorio: Estudio de las redes neuronales, Milestone},
  url = {https://github.com/BlancaCC/TFG-Estudio-de-las-redes-neuronales/milestones},
  urldate = {2022-02-13}
}

%%%%%% registro del número de horas de trabajo %%%%%%%%%%%%%
%% hoja de cálculo 
%% https://docs.google.com/spreadsheets/d/1TCcKQIKjKW9sMSU2f6obN9gHgv3c8UEdjmONkBlv42M/edit?usp=sharing
@online{TFG-hoja-calculo-horas-trabajo,
  author= {Blanca Cano Camarero},
  title ={Registro de trabajo en hoja de cálculo},
  url = {https://docs.google.com/spreadsheets/d/1TCcKQIKjKW9sMSU2f6obN9gHgv3c8UEdjmONkBlv42M/edit?usp=sharing},
  urldate = {2022-02-05}
}
