\input{header.tex}

\begin{document}

\chapter{Perceptron}

In order to simplify the Neural Networks' introduction, we are going 
to describe first 
what Perceptron is. 

The perceptron algorithm for halfspaces.
 \footnote{A half-space is either of the two parts into which a hyperplane divides a affine space. } 


 First, basic definitions: 

 The class of affine function  $L_d$ is the defined as follows:

 $$L_d = \{ h_{w,d}: w \in \mathbb{R}^d, b \in \mathbb R\}$$

Based on a target function
and  training examples fixed from a specific decision problem.  

We define a simple learning model as a : 
Let define the input space as $\mathcal{X} = \R^d$ where $d \in \N$ and $\X$ 
the $d$-dimensional Euclidian space. 

The output space is defining as $\mathcal{Y}={+1, -1}$. 

We specify the hypothesis set $\mathcal{H} = \{ h(\x) = sign(w^T \x +b)$ where $w, \x \in \X$
and $b \in \R$. 

The weight vector is $w$ and $\x$ are the elements from the training set. 

The model of $\mathcal{H}$ is called the \textit{perceptron}.  

And a  simple example 


\chapter{Multilayer perceptron}  

Multilayer perceptron is the result of compose multiple simple perceptron. 

TODO GIVE A EXAMPLE OF MULTILAYER PERCEPTRON. 


The MLP is often called a hard threshold neural network because the transformation
function is a hard threshold at zero, and they where traditionally the tanh, 

MLP is a type of neural network, based on the construction it has not recursion, 
otherwise we usually talk about RNN Recurrent Neural Networks. 




\end{document}